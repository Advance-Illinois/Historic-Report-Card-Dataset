{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd # pd.read_excel dependency\n",
    "import openpyxl # pd.read_excel dependency\n",
    "import jinja2 # dataframe styling dependency # OPTIONAL, you can delete this statement and just not run the cell that needs it (It's just a display cell)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import simplefilter\n",
    "import copy\n",
    "from itertools import product\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_INVENTORY=False\n",
    "WRITE_TO_FILE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1, STEP 4: Update the filename_crosswalk dictionary with the new year as a key and the new filename as a value\n",
    "filename_crosswalk = {\n",
    "    2024: \"24-RC-Pub-Data-Set.xlsx\",\n",
    "    2023: \"23-RC-Pub-Data-Set.xlsx\",\n",
    "    2022: \"2022-Report-Card-Public-Data-Set.xlsx\",\n",
    "    2021: \"2021-RC-Pub-Data-Set.xlsx\",\n",
    "    2020: \"2020-Report-Card-Public-Data-Set.xlsx\",\n",
    "    2019: \"2019-Report-Card-Public-Data-Set.xlsx\",\n",
    "    2018: \"Report-Card-Public-Data-Set.xlsx\",\n",
    "    2017: \"rc17.txt\",\n",
    "    2016: \"rc16.txt\",\n",
    "    2015: \"rc15.txt\",\n",
    "    2014: \"rc14.txt\",\n",
    "    2013: \"rc13.txt\",\n",
    "    2012: \"rc12.txt\",\n",
    "    2011: \"rc11u.txt\",\n",
    "    2010: \"rc10.txt\",\n",
    "    2009: \"rc09.txt\",\n",
    "    2008: \"rc08u.txt\"\n",
    "}\n",
    "\n",
    "START_YEAR = min(filename_crosswalk.keys())\n",
    "END_YEAR = max(filename_crosswalk.keys())\n",
    "\n",
    "assessment_crosswalk = {\n",
    "    2017: \"rc17_assessment.txt\",\n",
    "    2016: \"rc16_assessment.txt\",\n",
    "    2015: \"rc15-assessment.txt\"\n",
    "}\n",
    "\n",
    "# Section 1, STEP 5: New demographics\n",
    "DEMOGRAPHICS = ['Female', 'Male', 'White', 'Asian', 'Black', 'Latinx',\n",
    "       'American Indian or Alaska Native',\n",
    "       'Native Hawaiian or Other Pacific Islander', 'Two or More Races',\n",
    "       'EL', 'Low Income', 'Migrant', 'Homeless', 'IEP',\n",
    "       'Children with Disabilities', 'Unknown', 'Non Binary',\n",
    "       'Youth in Care']\n",
    "\n",
    "DEMO_INVENTORY = pd.read_excel('./Demographic Inventory.xlsx')\n",
    "DEMO_INVENTORY['Year'] = DEMO_INVENTORY['Year'].astype(int)\n",
    "DEMO_INVENTORY = DEMO_INVENTORY.set_index(['Year','Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_combos = DEMO_INVENTORY.copy()\n",
    "absent_combos = absent_combos[absent_combos['Disaggregated']].reset_index().drop(columns=\"Year\").groupby(['Metric']).sum().astype(bool)\n",
    "absent_combos = ~absent_combos.unstack()\n",
    "absent_combos = absent_combos[absent_combos].reset_index().rename(columns={'level_0':'Demographic'}).apply(lambda x: x['Metric'] + ' - ' + x['Demographic'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layout_file(short_year, sheet=0):\n",
    "    if int(short_year) > 12:\n",
    "        x = \"x\"\n",
    "    else:\n",
    "        x = \"\"\n",
    "    if short_year == \"12\" or short_year == \"16\" or short_year == \"15\":\n",
    "        return pd.read_excel(\"./data/RC\" + short_year + \"-layout.xls\" + x, header=None, sheet_name=sheet)\n",
    "    else:\n",
    "        return pd.read_excel(\"./data/RC\" + short_year + \"_layout.xls\" + x, header=None, sheet_name=sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_proficiency(layout_sheet, y):\n",
    "    if y == 2015:\n",
    "        layout_sheet.iloc[11046:11102, 1] = 'SCHOOL'\n",
    "        layout_sheet.iloc[11131:11187, 1] = 'DISTRICT'\n",
    "        layout_sheet.iloc[11216:11272, 1] = 'STATE'\n",
    "        return layout_sheet\n",
    "    elif y == 2016:\n",
    "        layout_sheet.iloc[11054:11110, 1] = 'SCHOOL'\n",
    "        layout_sheet.iloc[11139:11195, 1] = 'DISTRICT'\n",
    "        layout_sheet.iloc[11224:11280, 1] = 'STATE'\n",
    "        return layout_sheet\n",
    "    elif y == 2017:\n",
    "        layout_sheet.iloc[8113:8169, 1] = 'SCHOOL'\n",
    "        layout_sheet.iloc[8198:8254, 1] = 'DISTRICT'\n",
    "        layout_sheet.iloc[8283:8339, 1] = 'STATE'\n",
    "        return layout_sheet\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_demos = set()\n",
    "layout_demo_key = {\n",
    "    \"ASIAN\" : \"Asian\",\n",
    "    \"BLACK\" : \"Black\",\n",
    "    \"FEMALE\" : \"Female\",\n",
    "    \"HISPANIC\" : \"Latinx\",\n",
    "    \"IEP\" : \"IEP\",\n",
    "    \"LEP\" : \"EL\",\n",
    "    \"LOW INCOME\" : \"Low Income\",\n",
    "    \"MALE\" : \"Male\",\n",
    "    \"MIGRANT\" : \"Migrant\",\n",
    "    \"MULTIRACIAL\" : \"Two or More Races\",\n",
    "    \"NATIVE AMERICAN\" : \"American Indian or Alaska Native\",\n",
    "    \"NATIVE HAWAIIAN AND OTHERS\" : \"Native Hawaiian or Other Pacific Islander\",\n",
    "    \"TOW OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"TWO OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"WHITE\" : \"White\",\n",
    "}\n",
    "\n",
    "def clean_layout_file(layout_file, test=False):\n",
    "    layout_file = layout_file.rename(\n",
    "        columns={0: 'Column #', 1: 'Second Qualifier', 2: \"Demographic\", 5: \"Metric\"})\n",
    "    \n",
    "    layout_demos.update(layout_file['Demographic'].str.strip())\n",
    "    layout_file[\"Demographic\"] = layout_file['Demographic'].str.strip().replace(\n",
    "        layout_demo_key)\n",
    "    sq_mask = ~(layout_file['Second Qualifier'].isnull()) & (\n",
    "        layout_file['Second Qualifier'].str.strip() != '')\n",
    "    layout_file.loc[sq_mask, 'Demographic'] = layout_file.loc[sq_mask, 'Demographic'] + \\\n",
    "        ' (' + layout_file.loc[sq_mask, 'Second Qualifier'] + ')'\n",
    "    layout_file = layout_file.iloc[:, [0, 2, 5]]\n",
    "\n",
    "    # Drop rows that don't have a column number (header rows for categories)\n",
    "    layout_file['Column #'] = pd.to_numeric(\n",
    "        layout_file['Column #'], errors='coerce')\n",
    "    layout_file = layout_file[layout_file['Column #'].notnull()]\n",
    "    layout_file['Column #'] = layout_file['Column #'].astype(int)\n",
    "\n",
    "    # Reset index to column number\n",
    "    layout_file.index = layout_file['Column #'] - 1\n",
    "    layout_file.index.name = None\n",
    "\n",
    "    # Drop Column Number column\n",
    "    layout_file = layout_file.drop(columns='Column #')\n",
    "\n",
    "    # Replace demographic keys with Advance Illinois standard\n",
    "    # also clean up mistakes in demographics\n",
    "    # This makes it so that the demographic terms used in each year do not need to be tracked\n",
    "    layout_file['Metric'] = layout_file['Metric'].str.strip()\n",
    "    layout_file['Demographic'] = layout_file['Demographic'].str.strip()\n",
    "\n",
    "    # Create mask for all rows with demographics\n",
    "    mask = ~(layout_file[\"Demographic\"].isnull()) & (\n",
    "        layout_file[\"Demographic\"] != \"ALL\") & (layout_file[\"Demographic\"] != \"ALL STUDENTS\")\n",
    "    # Combine Metric and Demographic columns\n",
    "    layout_file.loc[mask, \"Metric\"] = layout_file.loc[mask, \"Metric\"].astype(\n",
    "        str) + \" - \" + layout_file.loc[mask, \"Demographic\"].astype(str)\n",
    "\n",
    "    layout_file['Metric'] = layout_file['Metric'].str.replace(r'\\bMEETSS\\b', 'MEETS', regex=True)\n",
    "\n",
    "    return layout_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = {}\n",
    "layout_assessment = {}\n",
    "# NOTE: the demographics column may have other notes besides just demographic info\n",
    "\n",
    "for year in range(2008, 2018):\n",
    "    s = \"{:02d}\".format(year - 2000)\n",
    "\n",
    "    # Grab Column Number, Demographic, and Metric columns\n",
    "    # Combine two demographic columns if there are two\n",
    "    layout[year] = get_layout_file(s)\n",
    "    layout[year] = clean_layout_file(layout[year])\n",
    "    if year > 2014:\n",
    "        layout_assessment[year] = get_layout_file(s, 1)\n",
    "        layout_assessment[year] = label_proficiency(\n",
    "            layout_assessment[year], year)\n",
    "        layout_assessment[year] = clean_layout_file(\n",
    "            layout_assessment[year])\n",
    "        layout_assessment[year] = layout_assessment[year].iloc[6:]\n",
    "        layout_assessment[year].index = layout_assessment[year].index + \\\n",
    "            layout[year].index[-1] + 1\n",
    "\n",
    "        layout[year] = pd.concat((layout[year], layout_assessment[year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace demographics in teacher data with Advance Illinois standard\n",
    "all_teacher_demos=set()\n",
    "layout_teacher_demo_key = {\n",
    "    \"ASIAN\" : \"Asian\",\n",
    "    \"BLACK\" : \"Black\",\n",
    "    \"FEMALE\" : \"Female\",\n",
    "    \"HISPANIC\" : \"Latinx\",\n",
    "    \"MALE\" : \"Male\",\n",
    "    \"NATIVE AMER\" : \"American Indian or Alaska Native\",\n",
    "    \"NATIVE AMERICAN\" : \"American Indian or Alaska Native\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\" : \"Native Hawaiian or Other Pacific Islander\",\n",
    "    \"TWO OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"UNKNOWN RACE\" : \"Unknown\",\n",
    "    \"WHITE\" : \"White\",\n",
    "}\n",
    "\n",
    "for year in layout.keys():\n",
    "    teacher_demos = layout[year]['Metric'].str.extract(r'% (.*) TEACH')[0]\n",
    "    teacher_demos = teacher_demos.dropna()\n",
    "    all_teacher_demos.update(teacher_demos)\n",
    "    \n",
    "    # This line drops the teacher measurements that aren't relevant to demographic replacement\n",
    "    teacher_demos = teacher_demos[(\n",
    "        teacher_demos != 'CLASSES NOT TAUGHT BY HIGHLY QUALIFIED') & (teacher_demos != 'of')] \n",
    "    \n",
    "    layout[year].loc[teacher_demos.index,\n",
    "                     'Demographic'] = teacher_demos.replace(layout_teacher_demo_key)\n",
    "\n",
    "    layout[year]['Metric'] = layout[year]['Metric'].str.replace(\n",
    "        'TEACH ER', 'TEACHER')\n",
    "    layout[year]['Metric'] = layout[year]['Metric'].str.replace(\n",
    "        'TEACHER- ', 'TEACHER - ')\n",
    "\n",
    "    layout[year].loc[teacher_demos.index, 'Metric'] = layout[year].loc[teacher_demos.index, 'Metric'].str.replace(\n",
    "        r'(% )(.*)( TEACH)', lambda m: m[1] + layout_teacher_demo_key[m[2]] + m[3], regex=True)\n",
    "    \n",
    "#pd.Series(list(all_teacher_demos)).sort_values().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_enroll_demos = set()\n",
    "layout_enroll_demo_key = {\n",
    "    \"ASIAN\" : \"Asian\",\n",
    "    \"BLACK\" : \"Black\",\n",
    "    \"HISPANIC\" : \"Latinx\",\n",
    "    \"NATIVE AMERICAN\" : \"American Indian or Alaska Native\",\n",
    "    \"HOMELESS\" : \"Homeless\",\n",
    "    \"I.E.P.\" : \"IEP\",\n",
    "    \"L.E.P.\" : \"EL\",\n",
    "    \"LOW-INCOME\" : \"Low Income\",\n",
    "    \"MULTIRACIAL/ETHNIC\" : \"Two or More Races\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\" : \"Native Hawaiian or Other Pacific Islander\",\n",
    "    \"TWO OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"WHITE\" : \"White\",\n",
    "}\n",
    "\n",
    "# Replace demographics in enrollment data with Advance Illinois standard\n",
    "for year in layout.keys():\n",
    "    enroll_demos = layout[year]['Metric'].str.extract(r'^\\w+ - (.*) %$')[0]\n",
    "    special_enroll = layout[year]['Metric'].str.extract(\n",
    "        r'(.*) (?:SCHOOL|DISTRICT|STATE) %$')[0]\n",
    "\n",
    "    enroll_demos = enroll_demos.dropna()\n",
    "    special_enroll = special_enroll.dropna()\n",
    "    all_enroll_demos.update(set(enroll_demos))\n",
    "    all_enroll_demos.update(set(special_enroll))\n",
    "\n",
    "    special_enroll = special_enroll[special_enroll.apply(\n",
    "        lambda x: x in layout_enroll_demo_key.keys())]\n",
    "\n",
    "    layout[year].loc[enroll_demos.index,\n",
    "                     'Demographic'] = enroll_demos.replace(layout_enroll_demo_key)\n",
    "    layout[year].loc[special_enroll.index,\n",
    "                     'Demographic'] = special_enroll.replace(layout_enroll_demo_key)\n",
    "\n",
    "    layout[year].loc[enroll_demos.index, 'Metric'] = layout[year].loc[enroll_demos.index, 'Metric'].str.replace(\n",
    "        r'(^\\w+ - )(.*)( %)$', lambda m: m[1] + layout_enroll_demo_key[m[2]] + m[3], regex=True)\n",
    "    layout[year].loc[special_enroll.index, 'Metric'] = layout[year].loc[special_enroll.index, 'Metric'].str.replace(\n",
    "        r'(.*)( (?:SCHOOL|DISTRICT|STATE) %$)', lambda m: layout_enroll_demo_key[m[1]] + m[2], regex=True)\n",
    "\n",
    "#pd.Series(list(all_enroll_demos)).sort_values().reset_index(drop=True).replace(layout_enroll_demo_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_card = {}\n",
    "\n",
    "if 'REPORT_CARD' in globals():\n",
    "    report_card = copy.deepcopy(REPORT_CARD)\n",
    "else:\n",
    "    for year in tqdm(filename_crosswalk.keys()):\n",
    "        if year > 2017:\n",
    "            wkbk = pd.read_excel(\n",
    "                \"./data/\" + filename_crosswalk[year], sheet_name=None, dtype='object')\n",
    "            wkbk.pop('Revision History', None)\n",
    "            wkbk.pop('Important Notes', None)\n",
    "\n",
    "            if year == 2021:\n",
    "                for k in wkbk.keys():\n",
    "                    wkbk[k].loc[(wkbk[k]['RCDTS'] == '310458000802001') & (\n",
    "                        wkbk[k]['Type'] == 'District'), 'RCDTS'] = '310458000800000'\n",
    "\n",
    "            report_card[year] = wkbk['General'].copy()\n",
    "\n",
    "            for k in filter(lambda x: x not in ['General', 'Finance'], wkbk.keys()):\n",
    "                report_card[year] = pd.merge(\n",
    "                    report_card[year], wkbk[k], on='RCDTS', how='outer', validate=\"1:1\", suffixes=('', f\"_{k}\"))\n",
    "\n",
    "        elif year > 2014:\n",
    "            report_card[year] = pd.read_csv(\"./data/\" + filename_crosswalk[year], sep=\";\",\n",
    "                                            header=None, dtype='object')\n",
    "\n",
    "            report_card_w_assessment = pd.read_csv(\"./data/\" + assessment_crosswalk[year], sep=\";\",\n",
    "                                                   header=None, dtype='object').iloc[:, 6:]\n",
    "\n",
    "            report_card_w_assessment.columns = report_card_w_assessment.columns + \\\n",
    "                layout_assessment[year].index[0] - 6\n",
    "\n",
    "            report_card[year] = pd.concat(\n",
    "                (report_card[year], report_card_w_assessment), axis=1).rename(columns=layout[year]['Metric'])\n",
    "        else:\n",
    "            report_card[year] = pd.read_csv(\"./data/\" + filename_crosswalk[year], sep=\";\",\n",
    "                                            header=None, dtype='object').rename(columns=layout[year]['Metric'])\n",
    "    REPORT_CARD = copy.deepcopy(report_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = pd.read_excel(\n",
    "    'Local Historic Crosswalk.xlsx', sheet_name='Name Crosswalk')\n",
    "crosswalk.index = crosswalk['Year']\n",
    "crosswalk = crosswalk.drop(columns='Year')\n",
    "crosswalk = crosswalk.loc[crosswalk.index.dropna()]\n",
    "\n",
    "demo_info = pd.read_excel(\n",
    "    'Local Historic Crosswalk.xlsx', sheet_name='Details')\n",
    "disagg_info = demo_info.groupby('Metric')['Disaggregated'].max()\n",
    "# True if index is ever disaggregated, false otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>% ISA Proficiency</td>\n",
       "      <td>% ISA Proficiency - Male %</td>\n",
       "      <td>% ISA Proficiency - Female</td>\n",
       "      <td>% ISA Proficiency - White</td>\n",
       "      <td>% ISA Proficiency - Black or African American</td>\n",
       "      <td>% ISA Proficiency - Hispanic or Latino</td>\n",
       "      <td>% ISA Proficiency - Asian</td>\n",
       "      <td>% ISA Proficiency - Native Hawaiian or Other P...</td>\n",
       "      <td>% ISA Proficiency - American Indian or Alaska ...</td>\n",
       "      <td>% ISA Proficiency - Two or More Races</td>\n",
       "      <td>...</td>\n",
       "      <td>% ISA Participation - Black or African American</td>\n",
       "      <td>% ISA Participation - Hispanic or Latino</td>\n",
       "      <td>% ISA Participation - Asian</td>\n",
       "      <td>% ISA Participation - Native Hawaiian or Other...</td>\n",
       "      <td>% ISA Participation - American Indian or Alask...</td>\n",
       "      <td>% ISA Participation - Two or More Races</td>\n",
       "      <td>% ISA Participation - Children with Disabilities</td>\n",
       "      <td>% ISA Participation - IEP</td>\n",
       "      <td>% ISA Participation - EL</td>\n",
       "      <td>% ISA Participation - Low Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>% ISA Proficiency</td>\n",
       "      <td>% ISA Proficiency - Male %</td>\n",
       "      <td>% ISA Proficiency - Female</td>\n",
       "      <td>% ISA Proficiency - White</td>\n",
       "      <td>% ISA Proficiency - Black or African American</td>\n",
       "      <td>% ISA Proficiency - Hispanic or Latino</td>\n",
       "      <td>% ISA Proficiency - Asian</td>\n",
       "      <td>% ISA Proficiency - Native Hawaiian or Other P...</td>\n",
       "      <td>% ISA Proficiency - American Indian or Alaska ...</td>\n",
       "      <td>% ISA Proficiency - Two or More Races</td>\n",
       "      <td>...</td>\n",
       "      <td>% ISA Participation - Black or African American</td>\n",
       "      <td>% ISA Participation - Hispanic or Latino</td>\n",
       "      <td>% ISA Participation - Asian</td>\n",
       "      <td>% ISA Participation - Native Hawaiian or Other...</td>\n",
       "      <td>% ISA Participation - American Indian or Alask...</td>\n",
       "      <td>% ISA Participation - Two or More Races</td>\n",
       "      <td>% ISA Participation - Children with Disabilities</td>\n",
       "      <td>% ISA Participation - IEP</td>\n",
       "      <td>% ISA Participation - EL</td>\n",
       "      <td>% ISA Participation - Low Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>% ISA Proficiency</td>\n",
       "      <td>% ISA Proficiency - Male %</td>\n",
       "      <td>% ISA Proficiency - Female</td>\n",
       "      <td>% ISA Proficiency - White</td>\n",
       "      <td>% ISA Proficiency - Black or African American</td>\n",
       "      <td>% ISA Proficiency - Hispanic or Latino</td>\n",
       "      <td>% ISA Proficiency - Asian</td>\n",
       "      <td>% ISA Proficiency - Native Hawaiian or Other P...</td>\n",
       "      <td>% ISA Proficiency - American Indian or Alaska ...</td>\n",
       "      <td>% ISA Proficiency - Two or More Races</td>\n",
       "      <td>...</td>\n",
       "      <td>% ISA Participation - Black or African American</td>\n",
       "      <td>% ISA Participation - Hispanic or Latino</td>\n",
       "      <td>% ISA Participation - Asian</td>\n",
       "      <td>% ISA Participation - Native Hawaiian or Other...</td>\n",
       "      <td>% ISA Participation - American Indian or Alask...</td>\n",
       "      <td>% ISA Participation - Two or More Races</td>\n",
       "      <td>% ISA Participation - Children with Disabilities</td>\n",
       "      <td>% ISA Participation - IEP</td>\n",
       "      <td>% ISA Participation - EL</td>\n",
       "      <td>% ISA Participation - Low Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>% ISA Proficiency</td>\n",
       "      <td>% ISA Proficiency - Male %</td>\n",
       "      <td>% ISA Proficiency - Female</td>\n",
       "      <td>% ISA Proficiency - White</td>\n",
       "      <td>% ISA Proficiency - Black or African American</td>\n",
       "      <td>% ISA Proficiency - Hispanic or Latino</td>\n",
       "      <td>% ISA Proficiency - Asian</td>\n",
       "      <td>% ISA Proficiency - Native Hawaiian or Other P...</td>\n",
       "      <td>% ISA Proficiency - American Indian or Alaska ...</td>\n",
       "      <td>% ISA Proficiency - Two or More Races</td>\n",
       "      <td>...</td>\n",
       "      <td>% ISA Participation - Black or African American</td>\n",
       "      <td>% ISA Participation - Hispanic or Latino</td>\n",
       "      <td>% ISA Participation - Asian</td>\n",
       "      <td>% ISA Participation - Native Hawaiian or Other...</td>\n",
       "      <td>% ISA Participation - American Indian or Alask...</td>\n",
       "      <td>% ISA Participation - Two or More Races</td>\n",
       "      <td>% ISA Participation - Children with Disabilities</td>\n",
       "      <td>% ISA Participation - IEP</td>\n",
       "      <td>% ISA Participation - EL</td>\n",
       "      <td>% ISA Participation - Low Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>% ISA Proficiency</td>\n",
       "      <td>% ISA Proficiency - Male %</td>\n",
       "      <td>% ISA Proficiency - Female</td>\n",
       "      <td>% ISA Proficiency - White</td>\n",
       "      <td>% ISA Proficiency - Black or African American</td>\n",
       "      <td>% ISA Proficiency - Hispanic or Latino</td>\n",
       "      <td>% ISA Proficiency - Asian</td>\n",
       "      <td>% ISA Proficiency - Native Hawaiian or Other P...</td>\n",
       "      <td>% ISA Proficiency - American Indian or Alaska ...</td>\n",
       "      <td>% ISA Proficiency - Two or More Races</td>\n",
       "      <td>...</td>\n",
       "      <td>% ISA Participation - Black or African American</td>\n",
       "      <td>% ISA Participation - Hispanic or Latino</td>\n",
       "      <td>% ISA Participation - Asian</td>\n",
       "      <td>% ISA Participation - Native Hawaiian or Other...</td>\n",
       "      <td>% ISA Participation - American Indian or Alask...</td>\n",
       "      <td>% ISA Participation - Two or More Races</td>\n",
       "      <td>% ISA Participation - Children with Disabilities</td>\n",
       "      <td>% ISA Participation - IEP</td>\n",
       "      <td>% ISA Participation - EL</td>\n",
       "      <td>% ISA Participation - Low Income</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                           1   \\\n",
       "2008                NaN                         NaN   \n",
       "2009                NaN                         NaN   \n",
       "2010                NaN                         NaN   \n",
       "2011                NaN                         NaN   \n",
       "2012                NaN                         NaN   \n",
       "2013                NaN                         NaN   \n",
       "2014                NaN                         NaN   \n",
       "2015                NaN                         NaN   \n",
       "2016                NaN                         NaN   \n",
       "2017                NaN                         NaN   \n",
       "2018                NaN                         NaN   \n",
       "2019  % ISA Proficiency  % ISA Proficiency - Male %   \n",
       "2020                NaN                         NaN   \n",
       "2021  % ISA Proficiency  % ISA Proficiency - Male %   \n",
       "2022  % ISA Proficiency  % ISA Proficiency - Male %   \n",
       "2023  % ISA Proficiency  % ISA Proficiency - Male %   \n",
       "2024  % ISA Proficiency  % ISA Proficiency - Male %   \n",
       "\n",
       "                              2                          3   \\\n",
       "2008                         NaN                        NaN   \n",
       "2009                         NaN                        NaN   \n",
       "2010                         NaN                        NaN   \n",
       "2011                         NaN                        NaN   \n",
       "2012                         NaN                        NaN   \n",
       "2013                         NaN                        NaN   \n",
       "2014                         NaN                        NaN   \n",
       "2015                         NaN                        NaN   \n",
       "2016                         NaN                        NaN   \n",
       "2017                         NaN                        NaN   \n",
       "2018                         NaN                        NaN   \n",
       "2019  % ISA Proficiency - Female  % ISA Proficiency - White   \n",
       "2020                         NaN                        NaN   \n",
       "2021  % ISA Proficiency - Female  % ISA Proficiency - White   \n",
       "2022  % ISA Proficiency - Female  % ISA Proficiency - White   \n",
       "2023  % ISA Proficiency - Female  % ISA Proficiency - White   \n",
       "2024  % ISA Proficiency - Female  % ISA Proficiency - White   \n",
       "\n",
       "                                                 4   \\\n",
       "2008                                            NaN   \n",
       "2009                                            NaN   \n",
       "2010                                            NaN   \n",
       "2011                                            NaN   \n",
       "2012                                            NaN   \n",
       "2013                                            NaN   \n",
       "2014                                            NaN   \n",
       "2015                                            NaN   \n",
       "2016                                            NaN   \n",
       "2017                                            NaN   \n",
       "2018                                            NaN   \n",
       "2019  % ISA Proficiency - Black or African American   \n",
       "2020                                            NaN   \n",
       "2021  % ISA Proficiency - Black or African American   \n",
       "2022  % ISA Proficiency - Black or African American   \n",
       "2023  % ISA Proficiency - Black or African American   \n",
       "2024  % ISA Proficiency - Black or African American   \n",
       "\n",
       "                                          5                          6   \\\n",
       "2008                                     NaN                        NaN   \n",
       "2009                                     NaN                        NaN   \n",
       "2010                                     NaN                        NaN   \n",
       "2011                                     NaN                        NaN   \n",
       "2012                                     NaN                        NaN   \n",
       "2013                                     NaN                        NaN   \n",
       "2014                                     NaN                        NaN   \n",
       "2015                                     NaN                        NaN   \n",
       "2016                                     NaN                        NaN   \n",
       "2017                                     NaN                        NaN   \n",
       "2018                                     NaN                        NaN   \n",
       "2019  % ISA Proficiency - Hispanic or Latino  % ISA Proficiency - Asian   \n",
       "2020                                     NaN                        NaN   \n",
       "2021  % ISA Proficiency - Hispanic or Latino  % ISA Proficiency - Asian   \n",
       "2022  % ISA Proficiency - Hispanic or Latino  % ISA Proficiency - Asian   \n",
       "2023  % ISA Proficiency - Hispanic or Latino  % ISA Proficiency - Asian   \n",
       "2024  % ISA Proficiency - Hispanic or Latino  % ISA Proficiency - Asian   \n",
       "\n",
       "                                                     7   \\\n",
       "2008                                                NaN   \n",
       "2009                                                NaN   \n",
       "2010                                                NaN   \n",
       "2011                                                NaN   \n",
       "2012                                                NaN   \n",
       "2013                                                NaN   \n",
       "2014                                                NaN   \n",
       "2015                                                NaN   \n",
       "2016                                                NaN   \n",
       "2017                                                NaN   \n",
       "2018                                                NaN   \n",
       "2019  % ISA Proficiency - Native Hawaiian or Other P...   \n",
       "2020                                                NaN   \n",
       "2021  % ISA Proficiency - Native Hawaiian or Other P...   \n",
       "2022  % ISA Proficiency - Native Hawaiian or Other P...   \n",
       "2023  % ISA Proficiency - Native Hawaiian or Other P...   \n",
       "2024  % ISA Proficiency - Native Hawaiian or Other P...   \n",
       "\n",
       "                                                     8   \\\n",
       "2008                                                NaN   \n",
       "2009                                                NaN   \n",
       "2010                                                NaN   \n",
       "2011                                                NaN   \n",
       "2012                                                NaN   \n",
       "2013                                                NaN   \n",
       "2014                                                NaN   \n",
       "2015                                                NaN   \n",
       "2016                                                NaN   \n",
       "2017                                                NaN   \n",
       "2018                                                NaN   \n",
       "2019  % ISA Proficiency - American Indian or Alaska ...   \n",
       "2020                                                NaN   \n",
       "2021  % ISA Proficiency - American Indian or Alaska ...   \n",
       "2022  % ISA Proficiency - American Indian or Alaska ...   \n",
       "2023  % ISA Proficiency - American Indian or Alaska ...   \n",
       "2024  % ISA Proficiency - American Indian or Alaska ...   \n",
       "\n",
       "                                         9   ...  \\\n",
       "2008                                    NaN  ...   \n",
       "2009                                    NaN  ...   \n",
       "2010                                    NaN  ...   \n",
       "2011                                    NaN  ...   \n",
       "2012                                    NaN  ...   \n",
       "2013                                    NaN  ...   \n",
       "2014                                    NaN  ...   \n",
       "2015                                    NaN  ...   \n",
       "2016                                    NaN  ...   \n",
       "2017                                    NaN  ...   \n",
       "2018                                    NaN  ...   \n",
       "2019  % ISA Proficiency - Two or More Races  ...   \n",
       "2020                                    NaN  ...   \n",
       "2021  % ISA Proficiency - Two or More Races  ...   \n",
       "2022  % ISA Proficiency - Two or More Races  ...   \n",
       "2023  % ISA Proficiency - Two or More Races  ...   \n",
       "2024  % ISA Proficiency - Two or More Races  ...   \n",
       "\n",
       "                                                   21  \\\n",
       "2008                                              NaN   \n",
       "2009                                              NaN   \n",
       "2010                                              NaN   \n",
       "2011                                              NaN   \n",
       "2012                                              NaN   \n",
       "2013                                              NaN   \n",
       "2014                                              NaN   \n",
       "2015                                              NaN   \n",
       "2016                                              NaN   \n",
       "2017                                              NaN   \n",
       "2018                                              NaN   \n",
       "2019  % ISA Participation - Black or African American   \n",
       "2020                                              NaN   \n",
       "2021  % ISA Participation - Black or African American   \n",
       "2022  % ISA Participation - Black or African American   \n",
       "2023  % ISA Participation - Black or African American   \n",
       "2024  % ISA Participation - Black or African American   \n",
       "\n",
       "                                            22                           23  \\\n",
       "2008                                       NaN                          NaN   \n",
       "2009                                       NaN                          NaN   \n",
       "2010                                       NaN                          NaN   \n",
       "2011                                       NaN                          NaN   \n",
       "2012                                       NaN                          NaN   \n",
       "2013                                       NaN                          NaN   \n",
       "2014                                       NaN                          NaN   \n",
       "2015                                       NaN                          NaN   \n",
       "2016                                       NaN                          NaN   \n",
       "2017                                       NaN                          NaN   \n",
       "2018                                       NaN                          NaN   \n",
       "2019  % ISA Participation - Hispanic or Latino  % ISA Participation - Asian   \n",
       "2020                                       NaN                          NaN   \n",
       "2021  % ISA Participation - Hispanic or Latino  % ISA Participation - Asian   \n",
       "2022  % ISA Participation - Hispanic or Latino  % ISA Participation - Asian   \n",
       "2023  % ISA Participation - Hispanic or Latino  % ISA Participation - Asian   \n",
       "2024  % ISA Participation - Hispanic or Latino  % ISA Participation - Asian   \n",
       "\n",
       "                                                     24  \\\n",
       "2008                                                NaN   \n",
       "2009                                                NaN   \n",
       "2010                                                NaN   \n",
       "2011                                                NaN   \n",
       "2012                                                NaN   \n",
       "2013                                                NaN   \n",
       "2014                                                NaN   \n",
       "2015                                                NaN   \n",
       "2016                                                NaN   \n",
       "2017                                                NaN   \n",
       "2018                                                NaN   \n",
       "2019  % ISA Participation - Native Hawaiian or Other...   \n",
       "2020                                                NaN   \n",
       "2021  % ISA Participation - Native Hawaiian or Other...   \n",
       "2022  % ISA Participation - Native Hawaiian or Other...   \n",
       "2023  % ISA Participation - Native Hawaiian or Other...   \n",
       "2024  % ISA Participation - Native Hawaiian or Other...   \n",
       "\n",
       "                                                     25  \\\n",
       "2008                                                NaN   \n",
       "2009                                                NaN   \n",
       "2010                                                NaN   \n",
       "2011                                                NaN   \n",
       "2012                                                NaN   \n",
       "2013                                                NaN   \n",
       "2014                                                NaN   \n",
       "2015                                                NaN   \n",
       "2016                                                NaN   \n",
       "2017                                                NaN   \n",
       "2018                                                NaN   \n",
       "2019  % ISA Participation - American Indian or Alask...   \n",
       "2020                                                NaN   \n",
       "2021  % ISA Participation - American Indian or Alask...   \n",
       "2022  % ISA Participation - American Indian or Alask...   \n",
       "2023  % ISA Participation - American Indian or Alask...   \n",
       "2024  % ISA Participation - American Indian or Alask...   \n",
       "\n",
       "                                           26  \\\n",
       "2008                                      NaN   \n",
       "2009                                      NaN   \n",
       "2010                                      NaN   \n",
       "2011                                      NaN   \n",
       "2012                                      NaN   \n",
       "2013                                      NaN   \n",
       "2014                                      NaN   \n",
       "2015                                      NaN   \n",
       "2016                                      NaN   \n",
       "2017                                      NaN   \n",
       "2018                                      NaN   \n",
       "2019  % ISA Participation - Two or More Races   \n",
       "2020                                      NaN   \n",
       "2021  % ISA Participation - Two or More Races   \n",
       "2022  % ISA Participation - Two or More Races   \n",
       "2023  % ISA Participation - Two or More Races   \n",
       "2024  % ISA Participation - Two or More Races   \n",
       "\n",
       "                                                    27  \\\n",
       "2008                                               NaN   \n",
       "2009                                               NaN   \n",
       "2010                                               NaN   \n",
       "2011                                               NaN   \n",
       "2012                                               NaN   \n",
       "2013                                               NaN   \n",
       "2014                                               NaN   \n",
       "2015                                               NaN   \n",
       "2016                                               NaN   \n",
       "2017                                               NaN   \n",
       "2018                                               NaN   \n",
       "2019  % ISA Participation - Children with Disabilities   \n",
       "2020                                               NaN   \n",
       "2021  % ISA Participation - Children with Disabilities   \n",
       "2022  % ISA Participation - Children with Disabilities   \n",
       "2023  % ISA Participation - Children with Disabilities   \n",
       "2024  % ISA Participation - Children with Disabilities   \n",
       "\n",
       "                             28                        29  \\\n",
       "2008                        NaN                       NaN   \n",
       "2009                        NaN                       NaN   \n",
       "2010                        NaN                       NaN   \n",
       "2011                        NaN                       NaN   \n",
       "2012                        NaN                       NaN   \n",
       "2013                        NaN                       NaN   \n",
       "2014                        NaN                       NaN   \n",
       "2015                        NaN                       NaN   \n",
       "2016                        NaN                       NaN   \n",
       "2017                        NaN                       NaN   \n",
       "2018                        NaN                       NaN   \n",
       "2019  % ISA Participation - IEP  % ISA Participation - EL   \n",
       "2020                        NaN                       NaN   \n",
       "2021  % ISA Participation - IEP  % ISA Participation - EL   \n",
       "2022  % ISA Participation - IEP  % ISA Participation - EL   \n",
       "2023  % ISA Participation - IEP  % ISA Participation - EL   \n",
       "2024  % ISA Participation - IEP  % ISA Participation - EL   \n",
       "\n",
       "                                    30  \n",
       "2008                               NaN  \n",
       "2009                               NaN  \n",
       "2010                               NaN  \n",
       "2011                               NaN  \n",
       "2012                               NaN  \n",
       "2013                               NaN  \n",
       "2014                               NaN  \n",
       "2015                               NaN  \n",
       "2016                               NaN  \n",
       "2017                               NaN  \n",
       "2018                               NaN  \n",
       "2019  % ISA Participation - Low Income  \n",
       "2020                               NaN  \n",
       "2021  % ISA Participation - Low Income  \n",
       "2022  % ISA Participation - Low Income  \n",
       "2023  % ISA Participation - Low Income  \n",
       "2024  % ISA Participation - Low Income  \n",
       "\n",
       "[17 rows x 31 columns]"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPLORATORY CELL\n",
    "search_string = \"% ISA\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for year in range(START_YEAR, 2018):\n",
    "    results.append(pd.Series(layout[year].loc[layout[year]['Metric'].str.contains(search_string, regex=False), 'Metric'], name=year).reset_index(drop=True))\n",
    "\n",
    "for year in range(2018, END_YEAR + 1):\n",
    "    results.append(pd.Series(report_card[year].columns[report_card[year].columns.str.contains(search_string, regex=False)], name=year).reset_index(drop=True))\n",
    "    \n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds all possible demographic categories to each column that has disaggregated data\n",
    "def add_demo_columns(columns, disagg_data):\n",
    "    out_columns = []\n",
    "    for col in columns:\n",
    "        out_columns.append(col)\n",
    "        if disagg_data[col]:\n",
    "            out_columns += list(map(lambda x: col + \" - \" + x,\n",
    "                                DEMOGRAPHICS))\n",
    "    return out_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2, Step 5: Typos and formatting issues\n",
    "# Replace demographic designations in report cards with standardized ones\n",
    "for year in range(2018, END_YEAR + 1):\n",
    "    report_card[year].columns = report_card[year].columns.str.strip()\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Black or African American', 'Black')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Hispanic or Latino', 'Latinx')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Hispanic', 'Latinx')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'CWD', 'Children with Disabilities')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Hawaiian/Pac Islander', 'Native Hawaiian or Other Pacific Islander')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Am Ind/Alaska Nat', 'American Indian or Alaska Native')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'MultiRace', 'Two or More Races')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'LowIncome', 'Low Income')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        r'\\bTwo or More Race\\b', 'Two or More Races', regex=True)\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        '% Homeless students IAR Mathematics Level 1 - Grade 32', '% Homeless students IAR Mathematics Level 1 - Grade 5')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Homeless students IAR Mathematics Level 1 - Grade 3.1', 'Homeless students IAR Mathematics Level 1 - Grade 5')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        '% ISA Proficiency - Male %', '% ISA Proficiency - Male')\n",
    "\n",
    "for year in range(2019, END_YEAR + 1):\n",
    "    report_card[year] = report_card[year].rename(\n",
    "        columns={'# ISA Participation - White Count': '# ISA Participation - White'})\n",
    "\n",
    "\n",
    "report_card[2018] = report_card[2018].rename(\n",
    "    columns={'Math Participation IEP %.1': 'Math Participation EL %', 'Math Participation Total IEP Count.1': 'Math Participation Total EL Count'})\n",
    "\n",
    "report_card[2019] = report_card[2019].rename(\n",
    "    columns={'% Math Participation - IEP.1': '% Math Participation - EL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all possible demographic categories to each column with disaggregated data\n",
    "columns = add_demo_columns(crosswalk.columns, disagg_info)\n",
    "columns = list(filter(lambda x: x not in list(absent_combos), columns))\n",
    "\n",
    "# Create new object filtering out old columns\n",
    "new_columns = list(filter(lambda x: x not in crosswalk.columns, columns))\n",
    "\n",
    "# Create new crosswalk with demographic info\n",
    "demo_crosswalk = crosswalk.copy()\n",
    "demo_crosswalk[new_columns] = np.nan\n",
    "\n",
    "for col in new_columns:\n",
    "    split = col.split(' - ')\n",
    "    if len(split) > 2:\n",
    "        metric = ' - '.join(split[:-1])\n",
    "        demo = split[-1]\n",
    "    else:\n",
    "        metric, demo = split\n",
    "    demo_formats = demo_info.copy().loc[demo_info['Metric'] == metric, [\n",
    "        'Year', 'Disaggregation Format', 'Special Format']]\n",
    "\n",
    "    if (demo in ['IEP', 'EL', 'Low Income', 'Homeless']):\n",
    "        demo_formats.loc[demo_formats['Special Format'].notnull(\n",
    "        ), 'Disaggregation Format'] = demo_formats.loc[demo_formats['Special Format'].notnull(), 'Special Format']\n",
    "\n",
    "    demo_formats = demo_formats.set_index('Year')['Disaggregation Format']\n",
    "\n",
    "    demo_formats = demo_formats.str.replace('demo', demo)\n",
    "    demo_formats = demo_formats.str.replace('DEMO', demo)\n",
    "    demo_crosswalk[col] = demo_formats\n",
    "\n",
    "master_data = pd.DataFrame(columns=['Year'] + columns)\n",
    "\n",
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scope_data(rename_vals, year, scope, demo_crosswalk, report_card, dropped_district_columns):\n",
    "    scoped_rename_vals = rename_vals.drop(\n",
    "        demo_crosswalk.loc[year, ['School Name', 'School Type']])\n",
    "\n",
    "    if scope == 'DISTRICT':\n",
    "        scoped_rename_vals.index = scoped_rename_vals.index.str.replace(\n",
    "            'SCHOOL', scope)\n",
    "        scoped_rename_vals.index = [\n",
    "            demo_crosswalk.loc[year, 'RCDTS']] + list(scoped_rename_vals.index[1:])\n",
    "        found_columns = [item.replace('SCHOOL', scope) for item in demo_crosswalk.loc[year].dropna(\n",
    "        ) if item.replace('SCHOOL', scope) in report_card[year].columns]\n",
    "        found_columns.remove(\"DISTRICT TYPE NAME\")\n",
    "        found_columns.remove(\"DISTRICT NAME\")\n",
    "    else:\n",
    "        scoped_rename_vals.index = scoped_rename_vals.index.str.replace(\n",
    "            'DISTRICT', scope).str.replace('SCHOOL', scope)\n",
    "        scoped_rename_vals.index = [\n",
    "            demo_crosswalk.loc[year, 'RCDTS']] + list(scoped_rename_vals.index[1:])\n",
    "\n",
    "        found_columns = [item.replace('DISTRICT', scope).replace('SCHOOL', scope) for item in demo_crosswalk.loc[year].dropna(\n",
    "        ) if item.replace('DISTRICT', scope).replace('SCHOOL', scope) in report_card[year].columns]\n",
    "\n",
    "    found_columns = [demo_crosswalk.loc[year, 'RCDTS'],\n",
    "                     'SCHOOL TYPE NAME'] + found_columns\n",
    "\n",
    "    scoped_data = report_card[year].loc[:, found_columns]\n",
    "    dropped_district_columns[year] = list(\n",
    "        set(scoped_rename_vals.index) - set(found_columns))\n",
    "    dropped_district_columns[year].sort()\n",
    "    scoped_data = scoped_data.rename(columns=scoped_rename_vals)\n",
    "\n",
    "    return scoped_data, dropped_district_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['RCDTS', 'Type', 'District Type', 'School Type', 'School Name','District Name', 'City', 'County', 'Title 1 Status']\n",
    "\n",
    "def adjust_typing(data, verbose=0):\n",
    "    for col in filter(lambda x: x not in text_columns, data.columns):\n",
    "        if verbose > 10:\n",
    "            print(col)\n",
    "        try:\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "        except:\n",
    "            data[col] = data[col].astype(str)\n",
    "            data[col] = data[col].str.replace(\",\", \"\")\n",
    "            data[col] = data[col].str.replace(\"*\", \"\")\n",
    "            data[col] = data[col].str.strip()\n",
    "            data[col] = data[col].str.replace(\"Not Provided\", \"\")\n",
    "            data[col] = data[col].str.replace(\"nan\", '')\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_inventory = demo_info.sort_values(by=['Index','Year']).reset_index()[['Year','Metric','Disaggregated']]\n",
    "demo_inventory[['All'] + DEMOGRAPHICS] = False\n",
    "demo_inventory[demo_inventory['Disaggregated']]\n",
    "demo_inventory = demo_inventory.set_index(['Year','Metric'])\n",
    "for i in range(START_YEAR, 2018):\n",
    "    demo_inventory.loc[(i, 'Type'),:] = False\n",
    "demo_inventory = demo_inventory.astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [02:44<00:00,  9.70s/it]\n"
     ]
    }
   ],
   "source": [
    "dropped_columns = {}\n",
    "dropped_district_columns = {}\n",
    "dropped_state_columns = {}\n",
    "\n",
    "for year in tqdm(range(START_YEAR, END_YEAR + 1)):\n",
    "    # the dropna here drops the columns that are not included in the crosswalk\n",
    "    # and thus not included in the report card for this year.\n",
    "    years_columns = demo_crosswalk.loc[year].dropna()\n",
    "    # swap index and vals for renaming\n",
    "\n",
    "    rename_vals = pd.Series(years_columns.index.values, index=years_columns)\n",
    "    # this list comprehension drops any columns that are not found in the report card this year\n",
    "    # this should drop demographic columns that are not found in this year, such as homeless enrollment\n",
    "    # counts for 2008 it should not however, drop columns that should be found in the report card.\n",
    "    # Because it is capable of dropping columns that should be there, the dropped columns are recorded in\n",
    "    # dropped_columns to be checked later\n",
    "    found_columns = [\n",
    "        item for item in years_columns if item in report_card[year].columns]\n",
    "\n",
    "    data = report_card[year].loc[:, found_columns]\n",
    "    dropped_columns[year] = list(set(years_columns) - set(found_columns))\n",
    "    dropped_columns[year].sort()\n",
    "\n",
    "    data = data.rename(columns=rename_vals)\n",
    "\n",
    "    # District and state level aggregation for 2008-2017\n",
    "    if year < 2018:\n",
    "        data['Type'] = 'School'\n",
    "\n",
    "        district_data, dropped_district_columns = scope_data(\n",
    "            rename_vals, year, 'DISTRICT', demo_crosswalk, report_card, dropped_district_columns)\n",
    "        district_data['RCD'] = district_data['RCDTS'].str[:9]\n",
    "        district_data = district_data[district_data['SCHOOL TYPE NAME'] != 'CHARTER SCH'].drop(\n",
    "            columns='SCHOOL TYPE NAME')\n",
    "        district_data['RCDTS'] = district_data['RCD'] + '000000'\n",
    "        district_data = district_data.groupby(\n",
    "            'RCD').max().reset_index(drop=True)\n",
    "        district_data['Type'] = 'District'\n",
    "\n",
    "        state_data, dropped_state_columns = scope_data(\n",
    "            rename_vals, year, 'STATE', demo_crosswalk, report_card, dropped_state_columns)\n",
    "        state_data = pd.DataFrame(state_data.max()).T.drop(\n",
    "            columns=['RCDTS', 'SCHOOL TYPE NAME', 'City', 'County'])\n",
    "        state_data['Type'] = 'Statewide'\n",
    "\n",
    "        data = pd.concat((data, district_data, state_data),\n",
    "                         axis=0, ignore_index=True)\n",
    "        data = data[['RCDTS', 'Type'] +\n",
    "                    [item for item in data.columns if item not in ['RCDTS', 'Type']]]\n",
    "\n",
    "    data = adjust_typing(data)\n",
    "    data['Year'] = year\n",
    "\n",
    "    metrics = pd.Series(data.columns).str.rsplit(' - ', expand=True, n=1).rename(columns={0:'Metric',1:'Demographic'})\n",
    "    mask = ~metrics['Demographic'].isin(DEMOGRAPHICS) & ~metrics['Demographic'].isnull()\n",
    "    metrics.loc[mask, 'Metric'] = metrics.loc[mask,'Metric'] + ' - ' + metrics.loc[mask, 'Demographic']\n",
    "    metrics.loc[mask, 'Demographic'] = None\n",
    "    metrics['Demographic'] = metrics['Demographic'].fillna('All')\n",
    "    metrics['Year'] = year\n",
    "    metrics = metrics.groupby(['Year','Metric']).agg(list)\n",
    "    metrics[['All'] + DEMOGRAPHICS] = False\n",
    "    for i in ['All'] + DEMOGRAPHICS:\n",
    "        metrics[i] = metrics['Demographic'].apply(lambda x: i in x)\n",
    "    metrics = metrics.drop(columns='Demographic')\n",
    "    demo_inventory.loc[metrics.index, ['All'] + DEMOGRAPHICS] = metrics\n",
    "\n",
    "    datasets[year] = data\n",
    "demo_inventory.loc[(slice(None),'Year'),'All'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2008: [],\n",
       " 2009: [],\n",
       " 2010: [],\n",
       " 2011: [],\n",
       " 2012: [],\n",
       " 2013: [],\n",
       " 2014: [],\n",
       " 2015: [],\n",
       " 2016: [],\n",
       " 2017: [],\n",
       " 2018: ['Five Essential Survey Ambitious Instruction.1',\n",
       "  'General Admin 2016-17 - Dollars.1',\n",
       "  'All students DLM Mathematics Emerging Grade 3.1'],\n",
       " 2019: ['Five Essential Survey Ambitious Instruction.1',\n",
       "  '% All Students (Peer Districts) - Black.1',\n",
       "  '% All Students (Peer Districts) - Latinx.1',\n",
       "  '% All Students (Peer Districts) - Asian.1',\n",
       "  '% All Students (Peer Districts) - Nat Haw/Other Pac Isndr.1',\n",
       "  '% All Students (Peer Districts) - American Indian or Alaska Native.1',\n",
       "  '% All Students (Peer Districts) - Two or More Races.1'],\n",
       " 2020: [],\n",
       " 2021: [],\n",
       " 2022: [],\n",
       " 2023: [],\n",
       " 2024: []}"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_ones = {}\n",
    "for i in range(START_YEAR, END_YEAR + 1):\n",
    "    c = report_card[i].columns.astype(str)\n",
    "    dot_ones[i] = (list(c[c.str.contains('.1', regex=False)]))\n",
    "dot_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset Creation and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13         Student Enrollment - Female\n",
       "29           Student Enrollment - Male\n",
       "58        Student Enrollment - Migrant\n",
       "700       Student Enrollment - Unknown\n",
       "973    Student Enrollment - Non Binary\n",
       "dtype: object"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absent_combos[absent_combos.str.startswith('Student Enrollment')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = pd.concat(datasets.values(), ignore_index=True)\n",
    "master_data = master_data.loc[:, ['Year'] + columns]\n",
    "master_data = master_data.apply(\n",
    "    lambda x: x.str.strip() if x.dtype == 'object' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data.loc[master_data['Type'] ==\n",
    "                'Statewide', 'RCDTS'] = '650000000800000'\n",
    "# Pre-2018 data fills district data to the school level, but this erases that in keeping with the newer protocol\n",
    "master_data.loc[master_data['Type'] == 'School', list(master_data.columns[master_data.columns.str.contains(\n",
    "    \"Teacher FTE\")]) + ['Pupil Teacher Ratio - Elementary', 'Pupil Teacher Ratio - High School']] = np.nan\n",
    "master_data.columns = master_data.columns.str.replace(\n",
    "    'Student Enrollment - ', '% Student Enrollment - ')\n",
    "master_data.columns = master_data.columns.str.replace(\n",
    "    'Total Teacher FTE - ', '% Teachers - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrollment_teacher_rename(x):\n",
    "    if x[1] == 'Student Enrollment':\n",
    "        return (x[0], '% Student Enrollment')\n",
    "    elif x[1] == 'Total Teacher FTE':\n",
    "        return (x[0], '% Teachers')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "mask = (slice(None),['Student Enrollment', 'Total Teacher FTE'])\n",
    "demo_inventory.loc[mask,'All'] = False\n",
    "demo_inventory.index = pd.MultiIndex.from_tuples(list(pd.DataFrame(demo_inventory.index)[0].apply(enrollment_teacher_rename)), names=['Year','Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(START_YEAR,END_YEAR + 1):\n",
    "    demo_inventory.loc[(i, 'Student Enrollment'), :] = False\n",
    "    demo_inventory.loc[(i, 'Student Enrollment'), 'All'] = True\n",
    "    demo_inventory.loc[(i, 'Total Teacher FTE'), :] = False\n",
    "    demo_inventory.loc[(i, 'Total Teacher FTE'), 'All'] = True\n",
    "\n",
    "demo_inventory = demo_inventory.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Student Enrollment</th>\n",
       "      <th>% Student Enrollment - White</th>\n",
       "      <th>% Student Enrollment - Asian</th>\n",
       "      <th>% Student Enrollment - Black</th>\n",
       "      <th>% Student Enrollment - Latinx</th>\n",
       "      <th>% Student Enrollment - American Indian or Alaska Native</th>\n",
       "      <th>% Student Enrollment - Native Hawaiian or Other Pacific Islander</th>\n",
       "      <th>% Student Enrollment - Two or More Races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19092</th>\n",
       "      <td>2011</td>\n",
       "      <td>2074806.0</td>\n",
       "      <td>51.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23830</th>\n",
       "      <td>2012</td>\n",
       "      <td>2066692.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28554</th>\n",
       "      <td>2013</td>\n",
       "      <td>2054155.0</td>\n",
       "      <td>50.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33208</th>\n",
       "      <td>2014</td>\n",
       "      <td>2046857.0</td>\n",
       "      <td>49.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37828</th>\n",
       "      <td>2015</td>\n",
       "      <td>2054556.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>17.5</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42414</th>\n",
       "      <td>2016</td>\n",
       "      <td>2041779.0</td>\n",
       "      <td>48.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>17.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47062</th>\n",
       "      <td>2017</td>\n",
       "      <td>2028162.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51816</th>\n",
       "      <td>2018</td>\n",
       "      <td>2001529.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56554</th>\n",
       "      <td>2019</td>\n",
       "      <td>1984519.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61274</th>\n",
       "      <td>2020</td>\n",
       "      <td>1957018.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65994</th>\n",
       "      <td>2021</td>\n",
       "      <td>1887316.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70705</th>\n",
       "      <td>2022</td>\n",
       "      <td>1869325.0</td>\n",
       "      <td>46.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75408</th>\n",
       "      <td>2023</td>\n",
       "      <td>1857790.0</td>\n",
       "      <td>45.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83397</th>\n",
       "      <td>2024</td>\n",
       "      <td>1851290.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Student Enrollment  % Student Enrollment - White  \\\n",
       "19092  2011           2074806.0                          51.4   \n",
       "23830  2012           2066692.0                          51.0   \n",
       "28554  2013           2054155.0                          50.6   \n",
       "33208  2014           2046857.0                          49.9   \n",
       "37828  2015           2054556.0                          49.3   \n",
       "42414  2016           2041779.0                          48.8   \n",
       "47062  2017           2028162.0                          48.5   \n",
       "51816  2018           2001529.0                          48.0   \n",
       "56554  2019           1984519.0                          47.6   \n",
       "61274  2020           1957018.0                          47.5   \n",
       "65994  2021           1887316.0                          46.7   \n",
       "70705  2022           1869325.0                          46.4   \n",
       "75408  2023           1857790.0                          45.9   \n",
       "83397  2024           1851290.0                          45.3   \n",
       "\n",
       "       % Student Enrollment - Asian  % Student Enrollment - Black  \\\n",
       "19092                           4.1                          18.3   \n",
       "23830                           4.2                          18.0   \n",
       "28554                           4.3                          17.6   \n",
       "33208                           4.5                          17.5   \n",
       "37828                           4.6                          17.5   \n",
       "42414                           4.7                          17.3   \n",
       "47062                           4.9                          17.0   \n",
       "51816                           5.1                          16.8   \n",
       "56554                           5.1                          16.7   \n",
       "61274                           5.2                          16.6   \n",
       "65994                           5.4                          16.6   \n",
       "70705                           5.4                          16.6   \n",
       "75408                           5.5                          16.5   \n",
       "83397                           5.6                          16.5   \n",
       "\n",
       "       % Student Enrollment - Latinx  \\\n",
       "19092                           23.0   \n",
       "23830                           23.6   \n",
       "28554                           24.1   \n",
       "33208                           24.6   \n",
       "37828                           25.1   \n",
       "42414                           25.5   \n",
       "47062                           25.7   \n",
       "51816                           26.2   \n",
       "56554                           26.4   \n",
       "61274                           26.6   \n",
       "65994                           27.0   \n",
       "70705                           27.2   \n",
       "75408                           27.5   \n",
       "83397                           28.1   \n",
       "\n",
       "       % Student Enrollment - American Indian or Alaska Native  \\\n",
       "19092                                                0.3         \n",
       "23830                                                0.3         \n",
       "28554                                                0.3         \n",
       "33208                                                0.3         \n",
       "37828                                                0.3         \n",
       "42414                                                0.3         \n",
       "47062                                                0.4         \n",
       "51816                                                0.3         \n",
       "56554                                                0.3         \n",
       "61274                                                0.3         \n",
       "65994                                                0.2         \n",
       "70705                                                0.3         \n",
       "75408                                                0.2         \n",
       "83397                                                0.2         \n",
       "\n",
       "       % Student Enrollment - Native Hawaiian or Other Pacific Islander  \\\n",
       "19092                                                0.1                  \n",
       "23830                                                0.1                  \n",
       "28554                                                0.1                  \n",
       "33208                                                0.1                  \n",
       "37828                                                0.1                  \n",
       "42414                                                0.1                  \n",
       "47062                                                0.1                  \n",
       "51816                                                0.1                  \n",
       "56554                                                0.1                  \n",
       "61274                                                0.1                  \n",
       "65994                                                0.1                  \n",
       "70705                                                0.1                  \n",
       "75408                                                0.1                  \n",
       "83397                                                0.1                  \n",
       "\n",
       "       % Student Enrollment - Two or More Races  \n",
       "19092                                       2.8  \n",
       "23830                                       2.8  \n",
       "28554                                       3.0  \n",
       "33208                                       3.1  \n",
       "37828                                       3.1  \n",
       "42414                                       3.2  \n",
       "47062                                       3.4  \n",
       "51816                                       3.5  \n",
       "56554                                       3.8  \n",
       "61274                                       3.8  \n",
       "65994                                       3.9  \n",
       "70705                                       4.1  \n",
       "75408                                       4.2  \n",
       "83397                                       4.2  "
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \"Type == 'Statewide' and Year >= 2011 and Year <= 2024\"\n",
    "master_data.query(query_string)[[\n",
    "    \"Year\",\n",
    "    \"Student Enrollment\",\n",
    "    \"% Student Enrollment - White\",\n",
    "    \"% Student Enrollment - Asian\",\n",
    "    \"% Student Enrollment - Black\",\n",
    "    \"% Student Enrollment - Latinx\",\n",
    "    \"% Student Enrollment - American Indian or Alaska Native\",\n",
    "    \"% Student Enrollment - Native Hawaiian or Other Pacific Islander\",\n",
    "    \"% Student Enrollment - Two or More Races\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertion_string = \"the demographic inventory has changed. If you have made updates that should \" + \\\n",
    "    \"impact the demographic inventory, please manually change the file to reflect the updates. \" + \\\n",
    "        \"Otherwise, changes made to this file are unexpectedly changing which columns & demographics are included in the file.\"\n",
    "assert demo_inventory.equals(DEMO_INVENTORY), assertion_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_negative_red(val):\n",
    "    if type(val) != bool:\n",
    "        return ''\n",
    "    color = 'green' if val else 'red'\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "if OVERWRITE_INVENTORY:\n",
    "    demo_inventory.reset_index().style.map(color_negative_red).to_excel('./Demographic Inventory.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Categorization and Writing to File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_columns(starters):\n",
    "    cols = []\n",
    "    for col in starters:\n",
    "        cols += list(master_data.columns[master_data.columns.str.startswith(col)])\n",
    "    return list(pd.Series(cols).drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_walk = demo_info.drop_duplicates(subset=['Metric', 'Category']).groupby(\n",
    "    ['Category']).agg({'Metric': list})\n",
    "# Section 4, Step 1: Add new category to list\n",
    "cat_walk = cat_walk.loc[['Identifier', 'Enrollment-Attendance', 'Student Performance',\n",
    "                         'CTE', 'Teachers-Admin', 'ACT', 'IAR', 'ISA', 'ISAT', 'PARCC', 'SAT'], :]\n",
    "cat_walk['Demo Metrics'] = cat_walk['Metric'].apply(find_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_sheets(master_data, cat_walk, district=False):\n",
    "    if district:\n",
    "        data = master_data[master_data['Type'] == 'District']\n",
    "        path = 'Historic RC District Data.xlsx'\n",
    "    else:\n",
    "        data = master_data\n",
    "        path = 'Historic Data.xlsx'\n",
    "\n",
    "    excel_writer = pd.ExcelWriter(path)\n",
    "\n",
    "    toc = demo_info.groupby(['Metric', 'Category'])[\n",
    "        'Disaggregated'].max().reset_index()\n",
    "    toc = toc.set_index('Category', drop=True)\n",
    "    toc = toc.loc[list(cat_walk.index), ['Metric', 'Disaggregated']]\n",
    "    toc = pd.merge(toc, (data.groupby(['Year']).count() > 1).replace(\n",
    "        {False: '', True: 'X'}).T, how='left', left_on='Metric', right_index=True)\n",
    "    toc.loc[toc['Metric'] == 'Year', range(START_YEAR, END_YEAR + 1)] = 'X'\n",
    "\n",
    "    toc.to_excel(excel_writer, sheet_name='Table of Contents')\n",
    "    demo_inventory.style.map(color_negative_red).to_excel(excel_writer, sheet_name='Demographic Inventory')\n",
    "\n",
    "    for cat in tqdm(cat_walk.index[1:]):\n",
    "        sheet_data = pd.merge(data[cat_walk.loc['Identifier', 'Metric']],\n",
    "                              data[cat_walk.loc[cat, 'Demo Metrics']], left_index=True, right_index=True)\n",
    "        years = sheet_data[['Year'] + cat_walk.loc[cat,\n",
    "                                                   'Demo Metrics']].groupby(['Year']).count().sum(axis=1).astype(bool)\n",
    "\n",
    "        year_high = years[years].index.max()\n",
    "        year_low = years[years].index.min()\n",
    "        sheet_data.query(\"Year >= @year_low and Year <= @year_high\").to_excel(\n",
    "            excel_writer, sheet_name=cat, index=False)\n",
    "    excel_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_TO_FILE:\n",
    "    if 'REPORT_CARD' in globals() or 'report_card' in globals():\n",
    "        del REPORT_CARD\n",
    "        del report_card\n",
    "\n",
    "    write_to_sheets(master_data, cat_walk, district=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_TO_FILE:\n",
    "    write_to_sheets(master_data, cat_walk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
