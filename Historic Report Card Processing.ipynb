{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd # pd.read_excel dependency\n",
    "import openpyxl # pd.read_excel dependency\n",
    "import jinja2 # dataframe styling dependency # OPTIONAL, you can delete this statement and just not run the cell that needs it (It's just a display cell)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import simplefilter\n",
    "import copy\n",
    "from itertools import product\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1, STEP 4: Update the filename_crosswalk dictionary with the new year as a key and the new filename as a value\n",
    "filename_crosswalk = {\n",
    "    2024: \"24-RC-Pub-Data-Set.xlsx\",\n",
    "    2023: \"23-RC-Pub-Data-Set.xlsx\",\n",
    "    2022: \"2022-Report-Card-Public-Data-Set.xlsx\",\n",
    "    2021: \"2021-RC-Pub-Data-Set.xlsx\",\n",
    "    2020: \"2020-Report-Card-Public-Data-Set.xlsx\",\n",
    "    2019: \"2019-Report-Card-Public-Data-Set.xlsx\",\n",
    "    2018: \"Report-Card-Public-Data-Set.xlsx\",\n",
    "    2017: \"rc17.txt\",\n",
    "    2016: \"rc16.txt\",\n",
    "    2015: \"rc15.txt\",\n",
    "    2014: \"rc14.txt\",\n",
    "    2013: \"rc13.txt\",\n",
    "    2012: \"rc12.txt\",\n",
    "    2011: \"rc11u.txt\",\n",
    "    2010: \"rc10.txt\",\n",
    "    2009: \"rc09.txt\",\n",
    "    2008: \"rc08u.txt\"\n",
    "}\n",
    "\n",
    "START_YEAR = min(filename_crosswalk.keys())\n",
    "END_YEAR = max(filename_crosswalk.keys())\n",
    "\n",
    "assessment_crosswalk = {\n",
    "    2017: \"rc17_assessment.txt\",\n",
    "    2016: \"rc16_assessment.txt\",\n",
    "    2015: \"rc15-assessment.txt\"\n",
    "}\n",
    "\n",
    "# Section 1, STEP 5: New demographics\n",
    "DEMOGRAPHICS = ['Female', 'Male', 'White', 'Asian', 'Black', 'Latinx',\n",
    "       'American Indian or Alaska Native',\n",
    "       'Native Hawaiian or Other Pacific Islander', 'Two or More Races',\n",
    "       'EL', 'IEP', 'Children with Disabilities', 'Low Income', 'Migrant', \n",
    "       'Homeless', 'Youth in Care', 'Unknown']\n",
    "\n",
    "DEMO_INVENTORY = pd.read_excel('./Demographic Inventory.xlsx')\n",
    "DEMO_INVENTORY['Index'] = DEMO_INVENTORY['Index'].astype(int)\n",
    "DEMO_INVENTORY['Year'] = DEMO_INVENTORY['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_combos = DEMO_INVENTORY.copy()\n",
    "absent_combos = absent_combos.set_index(['Year','Metric']).drop(columns=['Index','Category'])\n",
    "absent_combos = absent_combos[absent_combos['Disaggregated']].reset_index().groupby(['Metric']).sum().astype(bool)\n",
    "absent_combos = ~absent_combos.unstack()\n",
    "absent_combos = absent_combos[absent_combos].reset_index().rename(columns={'level_0':'Demographic'}).apply(lambda x: x['Metric'] + ' - ' + x['Demographic'],axis=1)\n",
    "absent_combos = absent_combos.str.replace('% Student Enrollment','Student Enrollment')\n",
    "absent_combos = absent_combos.str.replace('% Teachers','Total Teacher FTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_INVENTORY=False\n",
    "ALL_IN_ONE=True\n",
    "WRITE_TO_FILE=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layout_file(short_year, sheet=0):\n",
    "    if int(short_year) > 12:\n",
    "        x = \"x\"\n",
    "    else:\n",
    "        x = \"\"\n",
    "    if short_year == \"12\" or short_year == \"16\" or short_year == \"15\":\n",
    "        return pd.read_excel(\"./data/RC\" + short_year + \"-layout.xls\" + x, header=None, sheet_name=sheet)\n",
    "    else:\n",
    "        return pd.read_excel(\"./data/RC\" + short_year + \"_layout.xls\" + x, header=None, sheet_name=sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_proficiency(layout_sheet, y):\n",
    "    if y == 2015:\n",
    "        layout_sheet.iloc[11046:11102, 1] = 'SCHOOL'\n",
    "        layout_sheet.iloc[11131:11187, 1] = 'DISTRICT'\n",
    "        layout_sheet.iloc[11216:11272, 1] = 'STATE'\n",
    "        return layout_sheet\n",
    "    elif y == 2016:\n",
    "        layout_sheet.iloc[11054:11110, 1] = 'SCHOOL'\n",
    "        layout_sheet.iloc[11139:11195, 1] = 'DISTRICT'\n",
    "        layout_sheet.iloc[11224:11280, 1] = 'STATE'\n",
    "        return layout_sheet\n",
    "    elif y == 2017:\n",
    "        layout_sheet.iloc[8113:8169, 1] = 'SCHOOL'\n",
    "        layout_sheet.iloc[8198:8254, 1] = 'DISTRICT'\n",
    "        layout_sheet.iloc[8283:8339, 1] = 'STATE'\n",
    "        return layout_sheet\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_demos = set()\n",
    "layout_demo_key = {\n",
    "    \"ASIAN\" : \"Asian\",\n",
    "    \"BLACK\" : \"Black\",\n",
    "    \"FEMALE\" : \"Female\",\n",
    "    \"HISPANIC\" : \"Latinx\",\n",
    "    \"IEP\" : \"IEP\",\n",
    "    \"LEP\" : \"EL\",\n",
    "    \"LOW INCOME\" : \"Low Income\",\n",
    "    \"MALE\" : \"Male\",\n",
    "    \"MIGRANT\" : \"Migrant\",\n",
    "    \"MULTIRACIAL\" : \"Two or More Races\",\n",
    "    \"NATIVE AMERICAN\" : \"American Indian or Alaska Native\",\n",
    "    \"NATIVE HAWAIIAN AND OTHERS\" : \"Native Hawaiian or Other Pacific Islander\",\n",
    "    \"TOW OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"TWO OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"WHITE\" : \"White\",\n",
    "}\n",
    "\n",
    "def clean_layout_file(layout_file, test=False):\n",
    "    layout_file = layout_file.rename(\n",
    "        columns={0: 'Column #', 1: 'Second Qualifier', 2: \"Demographic\", 5: \"Metric\"})\n",
    "    \n",
    "    layout_demos.update(layout_file['Demographic'].str.strip())\n",
    "    layout_file[\"Demographic\"] = layout_file['Demographic'].str.strip().replace(\n",
    "        layout_demo_key)\n",
    "    sq_mask = ~(layout_file['Second Qualifier'].isnull()) & (\n",
    "        layout_file['Second Qualifier'].str.strip() != '')\n",
    "    layout_file.loc[sq_mask, 'Demographic'] = layout_file.loc[sq_mask, 'Demographic'] + \\\n",
    "        ' (' + layout_file.loc[sq_mask, 'Second Qualifier'] + ')'\n",
    "    layout_file = layout_file.iloc[:, [0, 2, 5]]\n",
    "\n",
    "    # Drop rows that don't have a column number (header rows for categories)\n",
    "    layout_file['Column #'] = pd.to_numeric(\n",
    "        layout_file['Column #'], errors='coerce')\n",
    "    layout_file = layout_file[layout_file['Column #'].notnull()]\n",
    "    layout_file['Column #'] = layout_file['Column #'].astype(int)\n",
    "\n",
    "    # Reset index to column number\n",
    "    layout_file.index = layout_file['Column #'] - 1\n",
    "    layout_file.index.name = None\n",
    "\n",
    "    # Drop Column Number column\n",
    "    layout_file = layout_file.drop(columns='Column #')\n",
    "\n",
    "    # Replace demographic keys with Advance Illinois standard\n",
    "    # also clean up mistakes in demographics\n",
    "    # This makes it so that the demographic terms used in each year do not need to be tracked\n",
    "    layout_file['Metric'] = layout_file['Metric'].str.strip()\n",
    "    layout_file['Demographic'] = layout_file['Demographic'].str.strip()\n",
    "\n",
    "    # Create mask for all rows with demographics\n",
    "    mask = ~(layout_file[\"Demographic\"].isnull()) & (\n",
    "        layout_file[\"Demographic\"] != \"ALL\") & (layout_file[\"Demographic\"] != \"ALL STUDENTS\")\n",
    "    # Combine Metric and Demographic columns\n",
    "    layout_file.loc[mask, \"Metric\"] = layout_file.loc[mask, \"Metric\"].astype(\n",
    "        str) + \" - \" + layout_file.loc[mask, \"Demographic\"].astype(str)\n",
    "\n",
    "    layout_file['Metric'] = layout_file['Metric'].str.replace(r'\\bMEETSS\\b', 'MEETS', regex=True)\n",
    "\n",
    "    return layout_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = {}\n",
    "layout_assessment = {}\n",
    "# NOTE: the demographics column may have other notes besides just demographic info\n",
    "\n",
    "for year in range(2008, 2018):\n",
    "    s = \"{:02d}\".format(year - 2000)\n",
    "\n",
    "    # Grab Column Number, Demographic, and Metric columns\n",
    "    # Combine two demographic columns if there are two\n",
    "    layout[year] = get_layout_file(s)\n",
    "    layout[year] = clean_layout_file(layout[year])\n",
    "    if year > 2014:\n",
    "        layout_assessment[year] = get_layout_file(s, 1)\n",
    "        layout_assessment[year] = label_proficiency(\n",
    "            layout_assessment[year], year)\n",
    "        layout_assessment[year] = clean_layout_file(\n",
    "            layout_assessment[year])\n",
    "        layout_assessment[year] = layout_assessment[year].iloc[6:]\n",
    "        layout_assessment[year].index = layout_assessment[year].index + \\\n",
    "            layout[year].index[-1] + 1\n",
    "\n",
    "        layout[year] = pd.concat((layout[year], layout_assessment[year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace demographics in teacher data with Advance Illinois standard\n",
    "all_teacher_demos=set()\n",
    "layout_teacher_demo_key = {\n",
    "    \"ASIAN\" : \"Asian\",\n",
    "    \"BLACK\" : \"Black\",\n",
    "    \"FEMALE\" : \"Female\",\n",
    "    \"HISPANIC\" : \"Latinx\",\n",
    "    \"MALE\" : \"Male\",\n",
    "    \"NATIVE AMER\" : \"American Indian or Alaska Native\",\n",
    "    \"NATIVE AMERICAN\" : \"American Indian or Alaska Native\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\" : \"Native Hawaiian or Other Pacific Islander\",\n",
    "    \"TWO OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"UNKNOWN RACE\" : \"Unknown\",\n",
    "    \"WHITE\" : \"White\",\n",
    "}\n",
    "\n",
    "for year in layout.keys():\n",
    "    teacher_demos = layout[year]['Metric'].str.extract(r'% (.*) TEACH')[0]\n",
    "    teacher_demos = teacher_demos.dropna()\n",
    "    all_teacher_demos.update(teacher_demos)\n",
    "    \n",
    "    # This line drops the teacher measurements that aren't relevant to demographic replacement\n",
    "    teacher_demos = teacher_demos[(\n",
    "        teacher_demos != 'CLASSES NOT TAUGHT BY HIGHLY QUALIFIED') & (teacher_demos != 'of')] \n",
    "    \n",
    "    layout[year].loc[teacher_demos.index,\n",
    "                     'Demographic'] = teacher_demos.replace(layout_teacher_demo_key)\n",
    "\n",
    "    layout[year]['Metric'] = layout[year]['Metric'].str.replace(\n",
    "        'TEACH ER', 'TEACHER')\n",
    "    layout[year]['Metric'] = layout[year]['Metric'].str.replace(\n",
    "        'TEACHER- ', 'TEACHER - ')\n",
    "\n",
    "    layout[year].loc[teacher_demos.index, 'Metric'] = layout[year].loc[teacher_demos.index, 'Metric'].str.replace(\n",
    "        r'(% )(.*)( TEACH)', lambda m: m[1] + layout_teacher_demo_key[m[2]] + m[3], regex=True)\n",
    "    \n",
    "#pd.Series(list(all_teacher_demos)).sort_values().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_enroll_demos = set()\n",
    "layout_enroll_demo_key = {\n",
    "    \"ASIAN\" : \"Asian\",\n",
    "    \"BLACK\" : \"Black\",\n",
    "    \"HISPANIC\" : \"Latinx\",\n",
    "    \"NATIVE AMERICAN\" : \"American Indian or Alaska Native\",\n",
    "    \"HOMELESS\" : \"Homeless\",\n",
    "    \"I.E.P.\" : \"IEP\",\n",
    "    \"L.E.P.\" : \"EL\",\n",
    "    \"LOW-INCOME\" : \"Low Income\",\n",
    "    \"MULTIRACIAL/ETHNIC\" : \"Two or More Races\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\" : \"Native Hawaiian or Other Pacific Islander\",\n",
    "    \"TWO OR MORE RACES\" : \"Two or More Races\",\n",
    "    \"WHITE\" : \"White\",\n",
    "}\n",
    "\n",
    "# Replace demographics in enrollment data with Advance Illinois standard\n",
    "for year in layout.keys():\n",
    "    enroll_demos = layout[year]['Metric'].str.extract(r'^\\w+ - (.*) %$')[0]\n",
    "    special_enroll = layout[year]['Metric'].str.extract(\n",
    "        r'(.*) (?:SCHOOL|DISTRICT|STATE) %$')[0]\n",
    "\n",
    "    enroll_demos = enroll_demos.dropna()\n",
    "    special_enroll = special_enroll.dropna()\n",
    "    all_enroll_demos.update(set(enroll_demos))\n",
    "    all_enroll_demos.update(set(special_enroll))\n",
    "\n",
    "    special_enroll = special_enroll[special_enroll.apply(\n",
    "        lambda x: x in layout_enroll_demo_key.keys())]\n",
    "\n",
    "    layout[year].loc[enroll_demos.index,\n",
    "                     'Demographic'] = enroll_demos.replace(layout_enroll_demo_key)\n",
    "    layout[year].loc[special_enroll.index,\n",
    "                     'Demographic'] = special_enroll.replace(layout_enroll_demo_key)\n",
    "\n",
    "    layout[year].loc[enroll_demos.index, 'Metric'] = layout[year].loc[enroll_demos.index, 'Metric'].str.replace(\n",
    "        r'(^\\w+ - )(.*)( %)$', lambda m: m[1] + layout_enroll_demo_key[m[2]] + m[3], regex=True)\n",
    "    layout[year].loc[special_enroll.index, 'Metric'] = layout[year].loc[special_enroll.index, 'Metric'].str.replace(\n",
    "        r'(.*)( (?:SCHOOL|DISTRICT|STATE) %$)', lambda m: layout_enroll_demo_key[m[1]] + m[2], regex=True)\n",
    "\n",
    "#pd.Series(list(all_enroll_demos)).sort_values().reset_index(drop=True).replace(layout_enroll_demo_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:46<00:00,  9.79s/it]\n"
     ]
    }
   ],
   "source": [
    "report_card = {}\n",
    "\n",
    "if 'REPORT_CARD' in globals():\n",
    "    report_card = copy.deepcopy(REPORT_CARD)\n",
    "else:\n",
    "    for year in tqdm(filename_crosswalk.keys()):\n",
    "        if year > 2017:\n",
    "            wkbk = pd.read_excel(\n",
    "                \"./data/\" + filename_crosswalk[year], sheet_name=None, dtype='object')\n",
    "            wkbk.pop('Revision History', None)\n",
    "            wkbk.pop('Important Notes', None)\n",
    "\n",
    "            for k in wkbk.keys():\n",
    "                wkbk[k]['RCDTS'] = wkbk[k]['RCDTS'].astype(str)\n",
    "                wkbk[k].loc[wkbk[k]['Type'] == 'Statewide', 'RCDTS'] = '650000000800000'\n",
    "\n",
    "            if year == 2021:\n",
    "                for k in wkbk.keys():\n",
    "                    wkbk[k].loc[(wkbk[k]['RCDTS'] == '310458000802001') & (\n",
    "                        wkbk[k]['Type'] == 'District'), 'RCDTS'] = '310458000800000'\n",
    "\n",
    "            report_card[year] = wkbk['General'].copy()\n",
    "\n",
    "            for k in filter(lambda x: x not in ['General', 'Finance'], wkbk.keys()):\n",
    "                report_card[year] = pd.merge(\n",
    "                    report_card[year], wkbk[k], on='RCDTS', how='outer', validate=\"1:1\", suffixes=('', f\"_{k}\"))\n",
    "\n",
    "        elif year > 2014:\n",
    "            report_card[year] = pd.read_csv(\"./data/\" + filename_crosswalk[year], sep=\";\",\n",
    "                                            header=None, dtype='object')\n",
    "\n",
    "            report_card_w_assessment = pd.read_csv(\"./data/\" + assessment_crosswalk[year], sep=\";\",\n",
    "                                                   header=None, dtype='object').iloc[:, 6:]\n",
    "\n",
    "            report_card_w_assessment.columns = report_card_w_assessment.columns + \\\n",
    "                layout_assessment[year].index[0] - 6\n",
    "\n",
    "            report_card[year] = pd.concat(\n",
    "                (report_card[year], report_card_w_assessment), axis=1).rename(columns=layout[year]['Metric'])\n",
    "        else:\n",
    "            report_card[year] = pd.read_csv(\"./data/\" + filename_crosswalk[year], sep=\";\",\n",
    "                                            header=None, dtype='object').rename(columns=layout[year]['Metric'])\n",
    "    REPORT_CARD = copy.deepcopy(report_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = pd.read_excel(\n",
    "    'Local Historic Crosswalk.xlsx', sheet_name='Name Crosswalk')\n",
    "crosswalk.index = crosswalk['Year']\n",
    "crosswalk = crosswalk.drop(columns='Year')\n",
    "crosswalk = crosswalk.loc[crosswalk.index.dropna()]\n",
    "\n",
    "demo_info = pd.read_excel(\n",
    "    'Local Historic Crosswalk.xlsx', sheet_name='Details')\n",
    "disagg_info = demo_info.groupby('Metric')['Disaggregated'].max()\n",
    "# True if index is ever disaggregated, false otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPLORATORY CELL\n",
    "search_string = \"fip\".upper()\n",
    "\n",
    "results = []\n",
    "\n",
    "for year in range(START_YEAR, 2018):\n",
    "    results.append(pd.Series(layout[year].loc[layout[year]['Metric'].str.upper().str.contains(search_string, regex=False), 'Metric'], name=year).reset_index(drop=True))\n",
    "\n",
    "for year in range(2018, END_YEAR + 1):\n",
    "    results.append(pd.Series(report_card[year].columns[report_card[year].columns.str.upper().str.contains(search_string, regex=False)], name=year).reset_index(drop=True))\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds all possible demographic categories to each column that has disaggregated data\n",
    "def add_demo_columns(columns, disagg_data):\n",
    "    out_columns = []\n",
    "    for col in columns:\n",
    "        out_columns.append(col)\n",
    "        if disagg_data[col]:\n",
    "            out_columns += list(map(lambda x: col + \" - \" + x,\n",
    "                                DEMOGRAPHICS))\n",
    "    return out_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2, Step 5: Typos and formatting issues\n",
    "# Replace demographic designations in report cards with standardized ones\n",
    "for year in range(2018, END_YEAR + 1):\n",
    "    report_card[year].columns = report_card[year].columns.str.strip()\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Black or African American', 'Black')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Hispanic or Latino', 'Latinx')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Hispanic', 'Latinx')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'CWD', 'Children with Disabilities')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Hawaiian/Pac Islander', 'Native Hawaiian or Other Pacific Islander')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Am Ind/Alaska Nat', 'American Indian or Alaska Native')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'MultiRace', 'Two or More Races')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'LowIncome', 'Low Income')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        r'\\bTwo or More Race\\b', 'Two or More Races', regex=True)\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        '% Homeless students IAR Mathematics Level 1 - Grade 32', '% Homeless students IAR Mathematics Level 1 - Grade 5')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        'Homeless students IAR Mathematics Level 1 - Grade 3.1', 'Homeless students IAR Mathematics Level 1 - Grade 5')\n",
    "    report_card[year].columns = report_card[year].columns.str.replace(\n",
    "        '% ISA Proficiency - Male %', '% ISA Proficiency - Male')\n",
    "\n",
    "for year in range(2019, END_YEAR + 1):\n",
    "    report_card[year] = report_card[year].rename(\n",
    "        columns={'# ISA Participation - White Count': '# ISA Participation - White'})\n",
    "\n",
    "\n",
    "report_card[2018] = report_card[2018].rename(\n",
    "    columns={'Math Participation IEP %.1': 'Math Participation EL %', 'Math Participation Total IEP Count.1': 'Math Participation Total EL Count'})\n",
    "\n",
    "report_card[2019] = report_card[2019].rename(\n",
    "    columns={'% Math Participation - IEP.1': '% Math Participation - EL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all possible demographic categories to each column with disaggregated data\n",
    "columns = add_demo_columns(crosswalk.columns, disagg_info)\n",
    "columns = list(filter(lambda x: x not in list(absent_combos), columns))\n",
    "\n",
    "# Create new object filtering out old columns\n",
    "new_columns = list(filter(lambda x: x not in crosswalk.columns, columns))\n",
    "\n",
    "# Create new crosswalk with demographic info\n",
    "demo_crosswalk = crosswalk.copy()\n",
    "demo_crosswalk[new_columns] = np.nan\n",
    "\n",
    "for col in new_columns:\n",
    "    split = col.split(' - ')\n",
    "    if len(split) > 2:\n",
    "        metric = ' - '.join(split[:-1])\n",
    "        demo = split[-1]\n",
    "    else:\n",
    "        metric, demo = split\n",
    "    demo_formats = demo_info.copy().loc[demo_info['Metric'] == metric, [\n",
    "        'Year', 'Disaggregation Format', 'Special Format']]\n",
    "\n",
    "    if (demo in ['IEP', 'EL', 'Low Income', 'Homeless']):\n",
    "        demo_formats.loc[demo_formats['Special Format'].notnull(\n",
    "        ), 'Disaggregation Format'] = demo_formats.loc[demo_formats['Special Format'].notnull(), 'Special Format']\n",
    "\n",
    "    demo_formats = demo_formats.set_index('Year')['Disaggregation Format']\n",
    "\n",
    "    demo_formats = demo_formats.str.replace('demo', demo)\n",
    "    demo_formats = demo_formats.str.replace('DEMO', demo)\n",
    "    demo_crosswalk[col] = demo_formats\n",
    "\n",
    "master_data = pd.DataFrame(columns=['Year'] + columns)\n",
    "\n",
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scope_data(rename_vals, year, scope, demo_crosswalk, report_card, dropped_district_columns):\n",
    "    scoped_rename_vals = rename_vals.drop(\n",
    "        demo_crosswalk.loc[year, ['School Name', 'School Type']])\n",
    "\n",
    "    if scope == 'DISTRICT':\n",
    "        scoped_rename_vals.index = scoped_rename_vals.index.str.replace(\n",
    "            'SCHOOL', scope)\n",
    "        scoped_rename_vals.index = [\n",
    "            demo_crosswalk.loc[year, 'RCDTS']] + list(scoped_rename_vals.index[1:])\n",
    "        found_columns = [item.replace('SCHOOL', scope) for item in demo_crosswalk.loc[year].dropna(\n",
    "        ) if item.replace('SCHOOL', scope) in report_card[year].columns]\n",
    "        found_columns.remove(\"DISTRICT TYPE NAME\")\n",
    "        found_columns.remove(\"DISTRICT NAME\")\n",
    "    else:\n",
    "        scoped_rename_vals.index = scoped_rename_vals.index.str.replace(\n",
    "            'DISTRICT', scope).str.replace('SCHOOL', scope)\n",
    "        scoped_rename_vals.index = [\n",
    "            demo_crosswalk.loc[year, 'RCDTS']] + list(scoped_rename_vals.index[1:])\n",
    "\n",
    "        found_columns = [item.replace('DISTRICT', scope).replace('SCHOOL', scope) for item in demo_crosswalk.loc[year].dropna(\n",
    "        ) if item.replace('DISTRICT', scope).replace('SCHOOL', scope) in report_card[year].columns]\n",
    "\n",
    "    found_columns = [demo_crosswalk.loc[year, 'RCDTS'],\n",
    "                     'SCHOOL TYPE NAME'] + found_columns\n",
    "\n",
    "    scoped_data = report_card[year].loc[:, found_columns]\n",
    "    dropped_district_columns[year] = list(\n",
    "        set(scoped_rename_vals.index) - set(found_columns))\n",
    "    dropped_district_columns[year].sort()\n",
    "    scoped_data = scoped_data.rename(columns=scoped_rename_vals)\n",
    "\n",
    "    return scoped_data, dropped_district_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3.5: Add new text metrics to text_columns list\n",
    "text_columns = ['RCDTS', 'Type', 'District Type', 'School Type', 'School Name','District Name', \n",
    "                'City', 'County', 'Title 1 Status', 'Summative Designation', \n",
    "                'Summative Designation: Student Group(s)']\n",
    "\n",
    "def adjust_typing(data, verbose=0, text_columns = text_columns):\n",
    "    for col in filter(lambda x: x not in text_columns, data.columns):\n",
    "        if verbose > 10:\n",
    "            print(col)\n",
    "        try:\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "        except:\n",
    "            # STEP 5.4.1: Handle new symbols\n",
    "            data[col] = data[col].astype(str)\n",
    "            data[col] = data[col].str.replace(\",\", \"\")\n",
    "            data[col] = data[col].str.replace(\"*\", \"\")\n",
    "            data[col] = data[col].str.strip()\n",
    "            data[col] = data[col].str.replace(\"Not Provided\", \"\")\n",
    "            data[col] = data[col].str.replace(\"nan\", '')\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_inventory = demo_info.sort_values(by=['Index','Year']).reset_index()[['Year','Metric','Disaggregated']]\n",
    "demo_inventory[['All'] + DEMOGRAPHICS] = False\n",
    "demo_inventory[demo_inventory['Disaggregated']]\n",
    "demo_inventory = demo_inventory.set_index(['Year','Metric'])\n",
    "for i in range(START_YEAR, 2018):\n",
    "    demo_inventory.loc[(i, 'Type'),:] = False\n",
    "demo_inventory = demo_inventory.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:41<00:00,  9.52s/it]\n"
     ]
    }
   ],
   "source": [
    "dropped_columns = {}\n",
    "dropped_district_columns = {}\n",
    "dropped_state_columns = {}\n",
    "\n",
    "for year in tqdm(range(START_YEAR, END_YEAR + 1)):\n",
    "    # the dropna here drops the columns that are not included in the crosswalk\n",
    "    # and thus not included in the report card for this year.\n",
    "    years_columns = demo_crosswalk.loc[year].dropna()\n",
    "    # swap index and vals for renaming\n",
    "\n",
    "    rename_vals = pd.Series(years_columns.index.values, index=years_columns)\n",
    "    # this list comprehension drops any columns that are not found in the report card this year\n",
    "    # this should drop demographic columns that are not found in this year, such as homeless enrollment\n",
    "    # counts for 2008 it should not however, drop columns that should be found in the report card.\n",
    "    # Because it is capable of dropping columns that should be there, the dropped columns are recorded in\n",
    "    # dropped_columns to be checked later\n",
    "    found_columns = [\n",
    "        item for item in years_columns if item in report_card[year].columns]\n",
    "\n",
    "    data = report_card[year].loc[:, found_columns]\n",
    "    dropped_columns[year] = list(set(years_columns) - set(found_columns))\n",
    "    dropped_columns[year].sort()\n",
    "\n",
    "    data = data.rename(columns=rename_vals)\n",
    "\n",
    "    # District and state level aggregation for 2008-2017\n",
    "    if year < 2018:\n",
    "        data['Type'] = 'School'\n",
    "\n",
    "        district_data, dropped_district_columns = scope_data(\n",
    "            rename_vals, year, 'DISTRICT', demo_crosswalk, report_card, dropped_district_columns)\n",
    "        district_data['RCD'] = district_data['RCDTS'].str[:11]\n",
    "        district_data = district_data[district_data['SCHOOL TYPE NAME'] != 'CHARTER SCH'].drop(\n",
    "            columns='SCHOOL TYPE NAME')\n",
    "        district_data['RCDTS'] = district_data['RCD'] + '0000'\n",
    "        district_data = district_data.groupby(\n",
    "            'RCD').max().reset_index(drop=True)\n",
    "        district_data['Type'] = 'District'\n",
    "\n",
    "        state_data, dropped_state_columns = scope_data(\n",
    "            rename_vals, year, 'STATE', demo_crosswalk, report_card, dropped_state_columns)\n",
    "        state_data = pd.DataFrame(state_data.max()).T.drop(\n",
    "            columns=['RCDTS', 'SCHOOL TYPE NAME', 'City', 'County'])\n",
    "        state_data['Type'] = 'Statewide'\n",
    "\n",
    "        data = pd.concat((data, district_data, state_data),\n",
    "                         axis=0, ignore_index=True)\n",
    "        data = data[['RCDTS', 'Type'] +\n",
    "                    [item for item in data.columns if item not in ['RCDTS', 'Type']]]\n",
    "\n",
    "    data = adjust_typing(data)\n",
    "    data['Year'] = year\n",
    "\n",
    "    metrics = pd.Series(data.columns).str.rsplit(' - ', expand=True, n=1).rename(columns={0:'Metric',1:'Demographic'})\n",
    "    mask = ~metrics['Demographic'].isin(DEMOGRAPHICS) & ~metrics['Demographic'].isnull()\n",
    "    metrics.loc[mask, 'Metric'] = metrics.loc[mask,'Metric'] + ' - ' + metrics.loc[mask, 'Demographic']\n",
    "    metrics.loc[mask, 'Demographic'] = None\n",
    "    metrics['Demographic'] = metrics['Demographic'].fillna('All')\n",
    "    metrics['Year'] = year\n",
    "    metrics = metrics.groupby(['Year','Metric']).agg(list)\n",
    "    metrics[['All'] + DEMOGRAPHICS] = False\n",
    "    for i in ['All'] + DEMOGRAPHICS:\n",
    "        metrics[i] = metrics['Demographic'].apply(lambda x: i in x)\n",
    "    metrics = metrics.drop(columns='Demographic')\n",
    "    demo_inventory.loc[metrics.index, ['All'] + DEMOGRAPHICS] = metrics\n",
    "\n",
    "\n",
    "    datasets[year] = data\n",
    "demo_inventory.loc[(slice(None),'Year'),'All'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2008: [],\n",
       " 2009: [],\n",
       " 2010: [],\n",
       " 2011: [],\n",
       " 2012: [],\n",
       " 2013: [],\n",
       " 2014: [],\n",
       " 2015: [],\n",
       " 2016: [],\n",
       " 2017: [],\n",
       " 2018: ['Five Essential Survey Ambitious Instruction.1',\n",
       "  'General Admin 2016-17 - Dollars.1',\n",
       "  'All students DLM Mathematics Emerging Grade 3.1'],\n",
       " 2019: ['Five Essential Survey Ambitious Instruction.1',\n",
       "  '% All Students (Peer Districts) - Black.1',\n",
       "  '% All Students (Peer Districts) - Latinx.1',\n",
       "  '% All Students (Peer Districts) - Asian.1',\n",
       "  '% All Students (Peer Districts) - Nat Haw/Other Pac Isndr.1',\n",
       "  '% All Students (Peer Districts) - American Indian or Alaska Native.1',\n",
       "  '% All Students (Peer Districts) - Two or More Races.1'],\n",
       " 2020: [],\n",
       " 2021: [],\n",
       " 2022: [],\n",
       " 2023: [],\n",
       " 2024: []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_ones = {}\n",
    "for i in range(START_YEAR, END_YEAR + 1):\n",
    "    c = report_card[i].columns.astype(str)\n",
    "    dot_ones[i] = (list(c[c.str.contains('.1', regex=False)]))\n",
    "dot_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset Creation and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = pd.concat(datasets.values(), ignore_index=True)\n",
    "master_data = master_data.loc[:, ['Year'] + columns]\n",
    "master_data = master_data.apply(\n",
    "    lambda x: x.str.strip() if x.dtype == 'object' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data.loc[master_data['Type'] ==\n",
    "                'Statewide', 'RCDTS'] = '650000000800000'\n",
    "# Pre-2018 data fills district data to the school level, but this erases that in keeping with the newer protocol\n",
    "master_data.loc[master_data['Type'] == 'School', list(master_data.columns[master_data.columns.str.contains(\n",
    "    \"Teacher FTE\")]) + ['Pupil Teacher Ratio - Elementary', 'Pupil Teacher Ratio - High School']] = np.nan\n",
    "master_data.columns = master_data.columns.str.replace(\n",
    "    'Student Enrollment - ', '% Student Enrollment - ')\n",
    "master_data.columns = master_data.columns.str.replace(\n",
    "    'Total Teacher FTE - ', '% Teachers - ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventory Management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrollment_teacher_rename(x):\n",
    "    if x[1] == 'Student Enrollment':\n",
    "        return (x[0], '% Student Enrollment')\n",
    "    elif x[1] == 'Total Teacher FTE':\n",
    "        return (x[0], '% Teachers')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "mask = (slice(None),['Student Enrollment', 'Total Teacher FTE'])\n",
    "demo_inventory.loc[mask,'All'] = False\n",
    "demo_inventory.index = pd.MultiIndex.from_tuples(list(pd.DataFrame(demo_inventory.index)[0].apply(enrollment_teacher_rename)), names=['Year','Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(START_YEAR,END_YEAR + 1):\n",
    "    demo_inventory.loc[(i, 'Student Enrollment'), :] = False\n",
    "    demo_inventory.loc[(i, 'Student Enrollment'), 'All'] = True\n",
    "    demo_inventory.loc[(i, 'Total Teacher FTE'), :] = False\n",
    "    demo_inventory.loc[(i, 'Total Teacher FTE'), 'All'] = True\n",
    "\n",
    "demo_inventory = demo_inventory.astype(bool)\n",
    "demo_inventory = pd.merge(demo_inventory.reset_index(),demo_info[['Year','Metric','Index','Category']],how='left',on=['Year','Metric'])\n",
    "demo_inventory.loc[demo_inventory['Metric'] == 'Type', 'Category'] = 'Identifier'\n",
    "demo_inventory.loc[demo_inventory['Metric'] == 'Type', 'Index'] = 2\n",
    "demo_inventory.loc[demo_inventory['Metric'] == '% Teachers', 'Category'] = 'Teachers-Admin'\n",
    "demo_inventory.loc[demo_inventory['Metric'] == '% Teachers', 'Index'] = 14\n",
    "demo_inventory.loc[demo_inventory['Metric'] == '% Student Enrollment', 'Category'] = 'Enrollment-Attendance'\n",
    "demo_inventory.loc[demo_inventory['Metric'] == '% Student Enrollment', 'Index'] = 9\n",
    "demo_inventory['Index'] = demo_inventory['Index'].astype(int)\n",
    "\n",
    "demo_inventory = demo_inventory[['Index','Category','Metric','Year','Disaggregated','All'] + DEMOGRAPHICS]\n",
    "demo_inventory = demo_inventory.sort_values(by=['Index','Metric','Year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_differences(original,new):\n",
    "    if new.equals(original):\n",
    "        print('The original dataframe and the new dataframe are identical.')\n",
    "        return\n",
    "    \n",
    "    if len(original.columns) > len(new.columns):\n",
    "        print('The new dataframe has fewer columns than the original dataframe.')\n",
    "        print('It is missing the following columns:', list(set(original.columns) - set(new.columns)))\n",
    "        return\n",
    "    elif len(original.columns) < len(new.columns):\n",
    "        print('The new dataframe has more columns than the original dataframe.')\n",
    "        print('It has the following extra columns:',list(set(new.columns) - set(original.columns)))\n",
    "        return\n",
    "    elif (original.columns != new.columns).any():\n",
    "        if (original.columns.sort_values() != new.columns.sort_values).any():\n",
    "            print('The new dataframe and the original have the same column names, but they are not in the same order.')\n",
    "        else:\n",
    "            differences = (original.columns != new.columns)\n",
    "            print('The new dataframe and the original dataframe have different column names. The following shows which columns differ:')\n",
    "            print('Original dataframe column names:',list(original.columns[differences]))\n",
    "            print('New      dataframe column names:',list(new.columns[differences]))\n",
    "        return\n",
    "\n",
    "    print('The column names are the same, and they are in the same order.')\n",
    "\n",
    "    if (original.dtypes != new.dtypes).any():\n",
    "        differences = original.dtypes != new.dtypes\n",
    "        print('The new dataframe does not have the same dtypes as the original. The following columns have different dtypes:')\n",
    "        print('Original:')\n",
    "        display(original.dtypes[differences])\n",
    "        print('New:')\n",
    "        display(new.dtypes[differences])\n",
    "\n",
    "    if original.shape[1] > new.shape[1]:\n",
    "        print('The new dataframe has fewer rows than the original dataframe.')\n",
    "    elif original.shape[1] < new.shape[1]:\n",
    "        print('The new dataframe has more rows than the original dataframe.')\n",
    "    else:\n",
    "        print('The new dataframe and the original dataframe have the same number of rows.')\n",
    "    \n",
    "    if original.sort_values(by=list(original.columns)).reset_index(drop=True).equals(new.sort_values(by=list(new.columns)).reset_index(drop=True)):\n",
    "        if original.sort_values(by=list(original.columns)).equals(new.sort_values(by=list(new.columns))):\n",
    "            print('The new dataframe and the original dataframe have the same rows, but they are shuffled. (Non-Index Agnostic)')\n",
    "        else:\n",
    "            print('The new dataframe and the original dataframe have the same rows, but they are shuffled. (Index Agnostic)')\n",
    "        return\n",
    "    else:\n",
    "        print('The sorted dataframes have the following index-agnostic differences in data:')\n",
    "        display(original.sort_values(by=list(original.columns)).reset_index(drop=True).compare(new.sort_values(by=list(new.columns)).reset_index(drop=True)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataframe and the new dataframe are identical.\n"
     ]
    }
   ],
   "source": [
    "# COMPARING THE ACTUAL INVENTORIES\n",
    "dataframe_differences(DEMO_INVENTORY,demo_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARING THE INVENTORIES WHERE THE CURRENT INVENTORY HAS THE MOST RECENT YEAR ERASED\n",
    "adding_new_year = False\n",
    "if adding_new_year:\n",
    "    dataframe_differences(DEMO_INVENTORY,demo_inventory[demo_inventory['Year'] != END_YEAR].sort_values(by=['Index','Metric','Year']).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertion_string = \"the demographic inventory has changed. If you have made updates that should \" + \\\n",
    "    \"impact the demographic inventory, please manually change the file to reflect the updates. \" + \\\n",
    "        \"Otherwise, changes made to this file are unexpectedly changing which columns & demographics are included in the file.\"\n",
    "assert demo_inventory.equals(DEMO_INVENTORY), assertion_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE_INVENTORY:\n",
    "    demo_inventory.sort_values(by=['Index','Metric','Year']).to_excel('./Demographic Inventory.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Categorization and Writing to File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_columns(starters):\n",
    "    cols = []\n",
    "    for col in starters:\n",
    "        cols += list(master_data.columns[master_data.columns.str.startswith(col)])\n",
    "    return list(pd.Series(cols).drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_walk = demo_inventory.drop_duplicates(subset=['Metric', 'Category']).groupby(\n",
    "    ['Category']).agg({'Metric': list})\n",
    "# Section 4, Step 1: Add new category to list\n",
    "cat_walk = cat_walk.loc[['Identifier', 'Enrollment-Attendance', 'Student Performance',\n",
    "                         'CTE', 'Teachers-Admin', 'ACT', 'IAR', 'ISA', 'ISAT', 'PARCC', 'SAT'], :]\n",
    "cat_walk['Demo Metrics'] = cat_walk['Metric'].apply(find_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_sheets(master_data, cat_walk, district=False, all_in_one=False):\n",
    "    if district:\n",
    "        data = master_data[master_data['Type'] == 'District']\n",
    "        path = 'Historic RC District Data.xlsx'\n",
    "    else:\n",
    "        data = master_data\n",
    "        path = 'Historic Data.xlsx'\n",
    "\n",
    "    if all_in_one:\n",
    "        master_data.to_csv('Historic RC Data One Sheet.csv',index=False)\n",
    "        return\n",
    "\n",
    "    excel_writer = pd.ExcelWriter(path)\n",
    "\n",
    "    toc = demo_info.groupby(['Metric', 'Category'])[\n",
    "        'Disaggregated'].max().reset_index()\n",
    "    toc = toc.set_index('Category', drop=True)\n",
    "    toc = toc.loc[list(cat_walk.index), ['Metric', 'Disaggregated']]\n",
    "    toc = pd.merge(toc, (data.groupby(['Year']).count() > 1).replace(\n",
    "        {False: '', True: 'X'}).T, how='left', left_on='Metric', right_index=True)\n",
    "    toc.loc[toc['Metric'] == 'Year', range(START_YEAR, END_YEAR + 1)] = 'X'\n",
    "\n",
    "    toc.to_excel(excel_writer, sheet_name='Table of Contents')\n",
    "    demo_inventory.to_excel(excel_writer, sheet_name='Demographic Inventory')\n",
    "\n",
    "    for cat in tqdm(cat_walk.index[1:]):\n",
    "        sheet_data = pd.merge(data[cat_walk.loc['Identifier', 'Metric']],\n",
    "                              data[cat_walk.loc[cat, 'Demo Metrics']], left_index=True, right_index=True)\n",
    "        years = sheet_data[['Year'] + cat_walk.loc[cat,\n",
    "                                                   'Demo Metrics']].groupby(['Year']).count().sum(axis=1).astype(bool)\n",
    "\n",
    "        year_high = years[years].index.max()\n",
    "        year_low = years[years].index.min()\n",
    "        sheet_data.query(\"Year >= @year_low and Year <= @year_high\").to_excel(\n",
    "            excel_writer, sheet_name=cat, index=False)\n",
    "    excel_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_TO_FILE and ALL_IN_ONE:\n",
    "    write_to_sheets(master_data,cat_walk,district=False,all_in_one=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:25<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "if WRITE_TO_FILE:\n",
    "    if 'REPORT_CARD' in globals() or 'report_card' in globals():\n",
    "        del REPORT_CARD\n",
    "        del report_card\n",
    "\n",
    "    write_to_sheets(master_data, cat_walk, district=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:10<00:00, 67.01s/it]\n"
     ]
    }
   ],
   "source": [
    "if WRITE_TO_FILE:\n",
    "    write_to_sheets(master_data, cat_walk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
